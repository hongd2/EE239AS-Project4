{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "import pprint\n",
    "from os import listdir\n",
    "from feature_extract import feature_extract\n",
    "\n",
    "HOUR_INDEX = 3\n",
    "MINUTE_INDEX = 4\n",
    "SECOND_INDEX = 5\n",
    "    \n",
    "files = listdir('../tweet_data')\n",
    "print(files)\n",
    "\n",
    "from os.path import splitext\n",
    "\n",
    "import re\n",
    "\n",
    "for fname in files:\n",
    "    m = re.search('#.+', splitext(files[0])[0])\n",
    "    if m:\n",
    "        hashtag = m.group()\n",
    "        print(\"Processing '%s'\" % hashtag)\n",
    "    outfile = splitext(fname)[0] + '.csv'\n",
    "    print(\"Output file name '%s'\" % outfile)\n",
    "    \n",
    "    f_handle = open('../tweet_data/'+fname, encoding=\"utf8\")\n",
    "    feature_extract(f_handle, outfile)\n",
    "    f_handle.close()\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "HOUR_INDEX = 3\n",
    "MINUTE_INDEX = 4\n",
    "SECOND_INDEX = 5\n",
    "\n",
    "def feature_extract(f, o_file):\n",
    "    import json\n",
    "    import time\n",
    "    from datetime import date\n",
    "\n",
    "    line = f.readline()\n",
    "    tweet = json.loads(line)\n",
    "\n",
    "    n_tweets = 0 # number of tweets per hour\n",
    "    n_followers = {} # uid -> (nfollower, ntweets) per hour\n",
    "    n_retweets = 0 # number of retweets per hour\n",
    "    num_window = 0 # total number of hours\n",
    "\n",
    "    user_follower = {}\n",
    "\n",
    "    # self defined features (for part 2)\n",
    "    # n_users:-  number of users tweeted per hour\n",
    "    # n_users_3:- number of users who tweeted 3 times or more per hour\n",
    "    n_len_100 = 0 # number of tweets with more than 100 characters per hour\n",
    "\n",
    "    # outputs\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"\n",
    "    output: n_tweets  n_retweets  sum_followers  max_followers  hour \\\n",
    "            avg_tweet_per_user  n_users  n_users_3  n_len_100\n",
    "    \"\"\"\n",
    "    output = np.empty([0, 9])\n",
    "\n",
    "    # get start hour from first tweet\n",
    "    start_time = list(time.localtime(tweet['firstpost_date']))\n",
    "    start_time[MINUTE_INDEX] = 0; start_time[SECOND_INDEX] = 0\n",
    "    nth_hour = start_time[HOUR_INDEX]\n",
    "    start_time = time.mktime(start_time)\n",
    "    start_date = date.fromtimestamp(start_time)\n",
    "    print \"Starting from time %s\" % time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time))\n",
    "\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    while len(line) != 0:\n",
    "        tweet = json.loads(line)\n",
    "        line = f.readline()\n",
    "        tweet_time = tweet['firstpost_date']\n",
    "        tweet_hour = time.localtime(tweet_time).tm_hour\n",
    "        if tweet_hour != nth_hour or start_date != date.fromtimestamp(float(tweet_time)):\n",
    "            print \"Finished processing %d tweets from hour %d, next date time %s\" %\\\n",
    "                  (n_tweets, nth_hour, time.strftime(time_format, time.localtime(tweet_time)))\n",
    "            # update output\n",
    "            tweets_per_user = np.array(n_followers.values())[:, 1]\n",
    "            new_hour = np.array([[n_tweets, n_retweets, sum(n_followers), max(n_followers), nth_hour, \\\n",
    "                                  np.mean(tweets_per_user), len(n_followers), sum(tweets_per_user >= 3), \\\n",
    "                                  n_len_100]])\n",
    "            output = np.append(output, new_hour, axis=0)\n",
    "            # clear & update hourly variables\n",
    "            num_window += 1\n",
    "            n_tweets = 0 # number of tweets per hour\n",
    "            n_followers = {} # number of followers of users posting the tweets per hour\n",
    "            n_retweets = 0 # number of retweets per hour\n",
    "            nth_hour = tweet_hour  # hour of the day\n",
    "            n_len_100 = 0\n",
    "\n",
    "        # extract features\n",
    "        n_tweets += 1\n",
    "        n_retweets += tweet['tweet']['retweet_count']\n",
    "        if tweet['tweet']['user']['id'] in n_followers:\n",
    "            # increment user tweet count\n",
    "            tweet_count = n_followers[tweet['tweet']['user']['id']][1] + 1\n",
    "            n_followers[tweet['tweet']['user']['id']] = (tweet['tweet']['user']['followers_count'], tweet_count)\n",
    "        else:\n",
    "            n_followers[tweet['tweet']['user']['id']] = (tweet['tweet']['user']['followers_count'], 1)\n",
    "        if (len(tweet['tweet']['text']) >= 100): n_len_100 += 1\n",
    "        user_follower[tweet['tweet']['user']['id']] = tweet['tweet']['user']['followers_count']\n",
    "        start_date = date.fromtimestamp(float(tweet_time))\n",
    "\n",
    "    print \"Outputting to '%s' ...\" % o_file\n",
    "    np.savetxt('data/' + o_file, output, delimiter=',')\n",
    "\n",
    "    print \"--------------------\"\n",
    "    print \"Total number of tweets %d\" % int(np.sum(output[:, 0]))\n",
    "    print \"Average number of tweets per hour %f\" % np.mean(output[:, 0])\n",
    "    print \"Average number of retweets %f\" % float(np.sum(output[:, 1]) / np.sum(output[:, 0]))\n",
    "    print \"Average number of followers of (%d) users %f\" %\\\n",
    "          (len(user_follower), float(sum(user_follower.values()) / float(len(user_follower))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "history = np.loadtxt('data/#SuperBowlhistogram')\n",
    "hours = np.loadtxt('data/#SuperBowlhistogramlabel')\n",
    "\n",
    "plt.cla()\n",
    "#plt.yscale('log')\n",
    "plt.plot(hours, history)\n",
    "plt.title('#SuperBowl Hourly Tweet Count')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Tweets')\n",
    "\n",
    "plt.xticks(range(len(hours))[::100], hours[::100])\n",
    "plt.savefig('graphs/#SuperBowl_tweet_count_histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "history = np.loadtxt('data/#NFLhistogram')\n",
    "hours = np.loadtxt('data/#NFLhistogramlabel')\n",
    "\n",
    "plt.cla()\n",
    "#plt.yscale('log')\n",
    "plt.plot(hours, history)\n",
    "plt.title('#NFL Hourly Tweet Count')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Tweets')\n",
    "\n",
    "plt.xticks(range(len(hours))[::100], hours[::100])\n",
    "plt.savefig('graphs/#NFL_tweet_count_histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Problem 2 and 3\n",
    "from os import listdir\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import LassoLars as lasso\n",
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.feature_selection import f_regression as freg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# directory name\n",
    "path = 'data/'\n",
    "\n",
    "# hashtag name\n",
    "hashtag = []\n",
    "\n",
    "# csv file name\n",
    "csv = []\n",
    "\n",
    "files = listdir(path)\n",
    "\n",
    "# append csv names into list\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        hashtag.append(f[7:-4])\n",
    "        csv.append(path + f)\n",
    "\n",
    "# start the training per hashtag file\n",
    "\n",
    "col_names = [\"n_tweets\", \"n_retweets\", \"sum_followers\", \"max_followers\", \"hour\", \"avg_tweet_per_user\", \"n_users\", \"n_users_3\", \"n_len_100\"]\n",
    "for c in csv:\n",
    "    print(c + \"\\n\")\n",
    "    csv_df = pd.read_csv(c, header=None, names=col_names)\n",
    "    # aggregate by hour of day\n",
    "    csv_df.sort_values(by='hour')\n",
    "    \n",
    "    LR2score = []\n",
    "    LR2fval = np.array([0,0,0,0])\n",
    "    LR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    LR3score = []\n",
    "    LR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    LR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    LogR2score = []\n",
    "    LogR2fval = np.array([0,0,0,0])\n",
    "    LogR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    LogR3score = []\n",
    "    LogR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    LogR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    SVR2score = []\n",
    "    SVR2fval = np.array([0,0,0,0])\n",
    "    SVR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    SVR3score = []\n",
    "    SVR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    SVR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    Lasso2score = []\n",
    "    Lasso2fval = np.array([0,0,0,0])\n",
    "    Lasso2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    Lasso3score = []\n",
    "    Lasso3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    Lasso3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    for hr in range(0,23):\n",
    "        #train data setup\n",
    "        data_prev = csv_df[csv_df['hour'] == hr].copy()\n",
    "        #features\n",
    "        data2X_train = data_prev[['n_retweets','sum_followers', 'max_followers', 'hour']].copy()\n",
    "        data3X_train = data_prev[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "        #targets\n",
    "        data2Y_train = data_prev[['n_tweets']].copy()\n",
    "        data3Y_train = data_prev[['n_tweets']].copy()\n",
    "        \n",
    "        #test data setup\n",
    "        data_next = csv_df[csv_df['hour'] == hr+1].copy()\n",
    "        #features\n",
    "        data2X_test = data_next[['n_retweets','sum_followers', 'max_followers', 'hour']].copy()\n",
    "        data3X_test = data_next[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "        #targets\n",
    "        data2Y_test = data_next[['n_tweets']].copy()\n",
    "        data3Y_test = data_next[['n_tweets']].copy()\n",
    "        \n",
    "        #create models\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "        LR2model = LR()\n",
    "        LR3model = LR()\n",
    "        #http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "        LogR2model = LogR()\n",
    "        LogR3model = LogR()\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "        SVR2model = SVR()\n",
    "        SVR3model = SVR()\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html\n",
    "        # Note for whoever writes report: LARS stands for Least Angle Regression\n",
    "        Lasso2model = lasso()\n",
    "        Lasso3model = lasso()\n",
    "        \n",
    "        #fit models\n",
    "        LR2model.fit(data2X_train, data2Y_train)\n",
    "        LR3model.fit(data3X_train, data3Y_train)\n",
    "        LogR2model.fit(data2X_train, data2Y_train.unstack())\n",
    "        LogR3model.fit(data3X_train, data3Y_train.unstack())\n",
    "        SVR2model.fit(data2X_train, data2Y_train.unstack())\n",
    "        SVR3model.fit(data3X_train, data3Y_train.unstack())\n",
    "        Lasso2model.fit(data2X_train, data2Y_train)\n",
    "        Lasso3model.fit(data3X_train, data3Y_train)\n",
    "        \n",
    "        #score models using r^2 scoring, f/t value and p value\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\n",
    "        \n",
    "        #problem 2 Lin Reg\n",
    "        LR2score.append(LR2model.score(data2X_test, data2Y_test))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        LR2fval = LR2fval + f\n",
    "        LR2pval = LR2pval + p\n",
    "        \n",
    "        #problem 3 Lin Reg\n",
    "        LR3score.append(LR3model.score(data3X_test, data3Y_test))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        LR3fval = LR3fval + f\n",
    "        LR3pval = LR3pval + p\n",
    "        \n",
    "        #problem 2 Log Reg\n",
    "        LogR2score.append(LogR2model.score(data2X_test, data2Y_test.unstack()))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        LogR2fval = LogR2fval + f\n",
    "        LogR2pval = LogR2pval + p\n",
    "        \n",
    "        #problem 3 Log Reg\n",
    "        LogR3score.append(LogR3model.score(data3X_test, data3Y_test.unstack()))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        LogR3fval = LogR3fval + f\n",
    "        LogR3pval = LogR3pval + p\n",
    "        \n",
    "        #problem 2 SVR \n",
    "        SVR2score.append(SVR2model.score(data2X_test, data2Y_test.unstack()))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        SVR2fval = SVR2fval + f\n",
    "        SVR2pval = SVR2pval + p\n",
    "        \n",
    "        #problem 3 SVR \n",
    "        SVR3score.append(SVR3model.score(data3X_test, data3Y_test.unstack()))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        SVR3fval = SVR3fval + f\n",
    "        SVR3pval = SVR3pval + p\n",
    "        \n",
    "        #problem 2 lARS\n",
    "        Lasso2score.append(Lasso2model.score(data2X_test, data2Y_test))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        Lasso2fval = Lasso2fval + f\n",
    "        Lasso2pval = Lasso2pval + p\n",
    "        \n",
    "        #problem 3 lARS\n",
    "        Lasso3score.append(Lasso3model.score(data3X_test, data3Y_test))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        Lasso3fval = Lasso3fval + f\n",
    "        Lasso3pval = Lasso3pval + p\n",
    "    \n",
    "    # print results\n",
    "    print(\"\\tLinear Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tLogistic Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LogR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LogR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LogR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LogR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LogR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LogR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LogR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LogR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LogR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LogR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tSupport Vector Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(SVR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(SVR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(SVR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(SVR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(SVR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(SVR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(SVR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(SVR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(SVR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(SVR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tLARS Lasso Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(Lasso2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(Lasso2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(Lasso2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(Lasso2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(Lasso2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(Lasso3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(Lasso3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(Lasso3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(Lasso3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(Lasso3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    break #remove to run all for all files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(LR2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a = (np.array([0,0,0,0,0]))\n",
    "a = a + (np.array([1,2,3,4,5]))\n",
    "a = a + np.array([1,2,3,4,5])\n",
    "a = a/2\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
