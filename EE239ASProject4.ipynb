{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt', 'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']\n",
      "Processing '#gohawks'\n",
      "Output file name 'tweets_#gohawks.csv'\n",
      "Starting from time 2014-12-28 14:00:00\n",
      "Finished processing 1 tweets from hour 14, next date time 2014-12-29 06:40:08\n",
      "Finished processing 1 tweets from hour 6, next date time 2014-12-29 07:27:13\n",
      "Finished processing 1 tweets from hour 7, next date time 2014-12-29 11:27:20\n",
      "Finished processing 1 tweets from hour 11, next date time 2014-12-29 12:10:38\n",
      "Finished processing 1 tweets from hour 12, next date time 2014-12-29 16:39:54\n",
      "Finished processing 1 tweets from hour 16, next date time 2014-12-30 10:03:35\n",
      "Finished processing 1 tweets from hour 10, next date time 2014-12-30 16:23:47\n",
      "Finished processing 2 tweets from hour 16, next date time 2014-12-31 08:20:51\n",
      "Finished processing 1 tweets from hour 8, next date time 2014-12-31 11:06:19\n",
      "Finished processing 1 tweets from hour 11, next date time 2014-12-31 17:26:05\n",
      "Finished processing 1 tweets from hour 17, next date time 2015-01-01 10:17:00\n",
      "Finished processing 1 tweets from hour 10, next date time 2015-01-01 11:11:20\n",
      "Finished processing 1 tweets from hour 11, next date time 2015-01-01 17:10:36\n",
      "Finished processing 1 tweets from hour 17, next date time 2015-01-02 08:40:47\n",
      "Finished processing 1 tweets from hour 8, next date time 2015-01-02 09:00:26\n",
      "Finished processing 1 tweets from hour 9, next date time 2015-01-02 12:38:35\n",
      "Finished processing 1 tweets from hour 12, next date time 2015-01-02 14:05:07\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-01-02 17:13:34\n",
      "Finished processing 1 tweets from hour 17, next date time 2015-01-02 20:40:55\n",
      "Finished processing 1 tweets from hour 20, next date time 2015-01-03 00:37:54\n",
      "Finished processing 1 tweets from hour 0, next date time 2015-01-03 08:17:14\n",
      "Finished processing 1 tweets from hour 8, next date time 2015-01-03 09:42:58\n",
      "Finished processing 1 tweets from hour 9, next date time 2015-01-03 13:55:36\n",
      "Finished processing 1 tweets from hour 13, next date time 2015-01-03 19:46:20\n",
      "Finished processing 1 tweets from hour 19, next date time 2015-01-03 20:02:06\n",
      "Finished processing 1 tweets from hour 20, next date time 2015-01-04 15:53:10\n",
      "Finished processing 1 tweets from hour 15, next date time 2015-01-04 17:00:31\n",
      "Finished processing 1 tweets from hour 17, next date time 2015-01-05 14:56:47\n",
      "Finished processing 2 tweets from hour 14, next date time 2015-01-06 12:56:33\n",
      "Finished processing 1 tweets from hour 12, next date time 2015-01-06 14:20:15\n",
      "Finished processing 2 tweets from hour 14, next date time 2015-01-06 16:05:18\n",
      "Finished processing 1 tweets from hour 16, next date time 2015-01-06 17:00:02\n",
      "Finished processing 2 tweets from hour 17, next date time 2015-01-06 22:02:41\n",
      "Finished processing 2 tweets from hour 22, next date time 2015-01-07 12:12:42\n",
      "Finished processing 1 tweets from hour 12, next date time 2015-01-07 15:40:50\n",
      "Finished processing 1 tweets from hour 15, next date time 2015-01-07 18:20:12\n",
      "Finished processing 1 tweets from hour 18, next date time 2015-01-08 08:18:39\n",
      "Finished processing 1 tweets from hour 8, next date time 2015-01-08 09:33:00\n",
      "Finished processing 1 tweets from hour 9, next date time 2015-01-08 12:32:24\n",
      "Finished processing 1 tweets from hour 12, next date time 2015-01-08 15:50:45\n",
      "Finished processing 1 tweets from hour 15, next date time 2015-01-08 16:42:57\n",
      "Finished processing 1 tweets from hour 16, next date time 2015-01-08 18:50:48\n",
      "Finished processing 1 tweets from hour 18, next date time 2015-01-08 22:38:34\n",
      "Finished processing 1 tweets from hour 22, next date time 2015-01-08 23:31:26\n",
      "Finished processing 1 tweets from hour 23, next date time 2015-01-09 06:56:17\n",
      "Finished processing 1 tweets from hour 6, next date time 2015-01-09 07:01:06\n",
      "Finished processing 2 tweets from hour 7, next date time 2015-01-09 08:16:13\n",
      "Finished processing 1 tweets from hour 8, next date time 2015-01-09 09:06:37\n",
      "Finished processing 3 tweets from hour 9, next date time 2015-01-09 10:33:02\n",
      "Finished processing 3 tweets from hour 10, next date time 2015-01-09 11:27:52\n",
      "Finished processing 1 tweets from hour 11, next date time 2015-01-09 12:07:31\n",
      "Finished processing 3 tweets from hour 12, next date time 2015-01-09 13:25:33\n",
      "Finished processing 1 tweets from hour 13, next date time 2015-01-09 14:23:34\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-01-09 15:04:16\n",
      "Finished processing 7 tweets from hour 15, next date time 2015-01-09 16:40:13\n",
      "Finished processing 1 tweets from hour 16, next date time 2015-01-09 18:13:18\n",
      "Finished processing 1 tweets from hour 18, next date time 2015-01-09 19:01:27\n",
      "Finished processing 1 tweets from hour 19, next date time 2015-01-09 22:11:35\n",
      "Finished processing 2 tweets from hour 22, next date time 2015-01-09 23:07:10\n",
      "Finished processing 3 tweets from hour 23, next date time 2015-01-10 00:04:29\n",
      "Finished processing 1 tweets from hour 0, next date time 2015-01-10 09:00:14\n",
      "Finished processing 2 tweets from hour 9, next date time 2015-01-10 12:08:21\n",
      "Finished processing 1 tweets from hour 12, next date time 2015-01-10 14:31:23\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-01-10 15:16:29\n",
      "Finished processing 3 tweets from hour 15, next date time 2015-01-10 16:02:30\n",
      "Finished processing 9 tweets from hour 16, next date time 2015-01-10 17:06:01\n",
      "Finished processing 8 tweets from hour 17, next date time 2015-01-10 18:10:42\n",
      "Finished processing 4 tweets from hour 18, next date time 2015-01-10 19:22:09\n",
      "Finished processing 2 tweets from hour 19, next date time 2015-01-10 20:02:27\n",
      "Finished processing 11 tweets from hour 20, next date time 2015-01-10 21:03:32\n",
      "Finished processing 2 tweets from hour 21, next date time 2015-01-10 22:13:53\n",
      "Finished processing 4 tweets from hour 22, next date time 2015-01-11 02:24:45\n",
      "Finished processing 1 tweets from hour 2, next date time 2015-01-11 10:07:10\n",
      "Finished processing 2 tweets from hour 10, next date time 2015-01-11 13:19:32\n",
      "Finished processing 4 tweets from hour 13, next date time 2015-01-11 14:41:10\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-01-11 15:27:29\n",
      "Finished processing 1 tweets from hour 15, next date time 2015-01-11 16:19:52\n",
      "Finished processing 2 tweets from hour 16, next date time 2015-01-11 17:11:42\n",
      "Finished processing 2 tweets from hour 17, next date time 2015-01-11 19:02:12\n",
      "Finished processing 1 tweets from hour 19, next date time 2015-01-11 20:08:05\n",
      "Finished processing 2 tweets from hour 20, next date time 2015-01-11 21:02:41\n",
      "Finished processing 1 tweets from hour 21, next date time 2015-01-11 23:51:23\n",
      "Finished processing 1 tweets from hour 23, next date time 2015-01-12 09:17:34\n",
      "Finished processing 3 tweets from hour 9, next date time 2015-01-12 10:14:52\n",
      "Finished processing 2 tweets from hour 10, next date time 2015-01-12 11:15:42\n",
      "Finished processing 1 tweets from hour 11, next date time 2015-01-12 12:21:56\n",
      "Finished processing 4 tweets from hour 12, next date time 2015-01-12 14:34:05\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-01-12 15:38:42\n",
      "Finished processing 1 tweets from hour 15, next date time 2015-01-12 16:55:09\n",
      "Finished processing 1 tweets from hour 16, next date time 2015-01-12 17:00:38\n",
      "Finished processing 3 tweets from hour 17, next date time 2015-01-12 19:17:26\n",
      "Finished processing 1 tweets from hour 19, next date time 2015-01-12 20:13:03\n",
      "Finished processing 2 tweets from hour 20, next date time 2015-01-12 22:19:41\n",
      "Finished processing 3 tweets from hour 22, next date time 2015-01-13 06:23:59\n",
      "Finished processing 1 tweets from hour 6, next date time 2015-01-13 07:17:01\n",
      "Finished processing 3 tweets from hour 7, next date time 2015-01-13 08:17:55\n",
      "Finished processing 1 tweets from hour 8, next date time 2015-01-13 12:07:55\n",
      "Finished processing 3 tweets from hour 12, next date time 2015-01-13 13:26:36\n",
      "Finished processing 1 tweets from hour 13, next date time 2015-01-13 14:01:10\n",
      "Finished processing 2 tweets from hour 14, next date time 2015-01-13 15:25:03\n",
      "Finished processing 2 tweets from hour 15, next date time 2015-01-13 16:05:14\n",
      "Finished processing 4 tweets from hour 16, next date time 2015-01-13 17:05:08\n",
      "Finished processing 5 tweets from hour 17, next date time 2015-01-13 18:06:48\n",
      "Finished processing 9 tweets from hour 18, next date time 2015-01-13 19:12:02\n",
      "Finished processing 8 tweets from hour 19, next date time 2015-01-13 20:08:06\n",
      "Finished processing 11 tweets from hour 20, next date time 2015-01-13 21:02:35\n",
      "Finished processing 4 tweets from hour 21, next date time 2015-01-13 22:08:54\n",
      "Finished processing 5 tweets from hour 22, next date time 2015-01-13 23:56:39\n",
      "Finished processing 1 tweets from hour 23, next date time 2015-01-14 00:04:41\n",
      "Finished processing 21 tweets from hour 0, next date time 2015-01-14 01:01:33\n",
      "Finished processing 10 tweets from hour 1, next date time 2015-01-14 02:00:22\n",
      "Finished processing 12 tweets from hour 2, next date time 2015-01-14 03:18:33\n",
      "Finished processing 6 tweets from hour 3, next date time 2015-01-14 04:03:18\n",
      "Finished processing 22 tweets from hour 4, next date time 2015-01-14 05:00:31\n",
      "Finished processing 31 tweets from hour 5, next date time 2015-01-14 06:01:49\n",
      "Finished processing 40 tweets from hour 6, next date time 2015-01-14 07:00:07\n",
      "Finished processing 69 tweets from hour 7, next date time 2015-01-14 08:00:22\n",
      "Finished processing 135 tweets from hour 8, next date time 2015-01-14 09:00:24\n",
      "Finished processing 150 tweets from hour 9, next date time 2015-01-14 10:00:07\n",
      "Finished processing 132 tweets from hour 10, next date time 2015-01-14 11:00:00\n",
      "Finished processing 122 tweets from hour 11, next date time 2015-01-14 12:00:15\n",
      "Finished processing 135 tweets from hour 12, next date time 2015-01-14 13:00:02\n",
      "Finished processing 170 tweets from hour 13, next date time 2015-01-14 14:00:34\n",
      "Finished processing 135 tweets from hour 14, next date time 2015-01-14 15:00:18\n",
      "Finished processing 127 tweets from hour 15, next date time 2015-01-14 16:00:12\n",
      "Finished processing 88 tweets from hour 16, next date time 2015-01-14 17:00:06\n",
      "Finished processing 82 tweets from hour 17, next date time 2015-01-14 18:00:00\n",
      "Finished processing 70 tweets from hour 18, next date time 2015-01-14 19:00:01\n",
      "Finished processing 128 tweets from hour 19, next date time 2015-01-14 20:00:16\n",
      "Finished processing 128 tweets from hour 20, next date time 2015-01-14 21:00:20\n",
      "Finished processing 110 tweets from hour 21, next date time 2015-01-14 22:00:44\n",
      "Finished processing 84 tweets from hour 22, next date time 2015-01-14 23:00:51\n",
      "Finished processing 41 tweets from hour 23, next date time 2015-01-15 00:01:21\n",
      "Finished processing 12 tweets from hour 0, next date time 2015-01-15 01:00:24\n",
      "Finished processing 20 tweets from hour 1, next date time 2015-01-15 02:09:58\n",
      "Finished processing 17 tweets from hour 2, next date time 2015-01-15 03:01:27\n",
      "Finished processing 13 tweets from hour 3, next date time 2015-01-15 04:02:06\n",
      "Finished processing 20 tweets from hour 4, next date time 2015-01-15 05:01:20\n",
      "Finished processing 30 tweets from hour 5, next date time 2015-01-15 06:00:45\n",
      "Finished processing 46 tweets from hour 6, next date time 2015-01-15 07:00:02\n",
      "Finished processing 100 tweets from hour 7, next date time 2015-01-15 08:00:01\n",
      "Finished processing 171 tweets from hour 8, next date time 2015-01-15 09:00:02\n",
      "Finished processing 142 tweets from hour 9, next date time 2015-01-15 10:01:21\n",
      "Finished processing 83 tweets from hour 10, next date time 2015-01-15 11:01:07\n",
      "Finished processing 170 tweets from hour 11, next date time 2015-01-15 12:00:10\n",
      "Finished processing 175 tweets from hour 12, next date time 2015-01-15 13:00:11\n",
      "Finished processing 164 tweets from hour 13, next date time 2015-01-15 14:00:08\n",
      "Finished processing 157 tweets from hour 14, next date time 2015-01-15 15:00:06\n",
      "Finished processing 149 tweets from hour 15, next date time 2015-01-15 16:00:33\n",
      "Finished processing 109 tweets from hour 16, next date time 2015-01-15 17:00:23\n",
      "Finished processing 165 tweets from hour 17, next date time 2015-01-15 18:00:33\n",
      "Finished processing 141 tweets from hour 18, next date time 2015-01-15 19:00:28\n",
      "Finished processing 173 tweets from hour 19, next date time 2015-01-15 20:00:32\n",
      "Finished processing 101 tweets from hour 20, next date time 2015-01-15 21:00:55\n",
      "Finished processing 95 tweets from hour 21, next date time 2015-01-15 22:01:29\n",
      "Finished processing 83 tweets from hour 22, next date time 2015-01-15 23:01:06\n",
      "Finished processing 22 tweets from hour 23, next date time 2015-01-16 00:00:05\n",
      "Finished processing 62 tweets from hour 0, next date time 2015-01-16 01:01:01\n",
      "Finished processing 10 tweets from hour 1, next date time 2015-01-16 02:26:39\n",
      "Finished processing 4 tweets from hour 2, next date time 2015-01-16 03:03:06\n",
      "Finished processing 4 tweets from hour 3, next date time 2015-01-16 04:01:35\n",
      "Finished processing 25 tweets from hour 4, next date time 2015-01-16 05:03:20\n",
      "Finished processing 34 tweets from hour 5, next date time 2015-01-16 06:00:36\n",
      "Finished processing 78 tweets from hour 6, next date time 2015-01-16 07:00:13\n",
      "Finished processing 306 tweets from hour 7, next date time 2015-01-16 08:00:00\n",
      "Finished processing 479 tweets from hour 8, next date time 2015-01-16 09:00:00\n",
      "Finished processing 500 tweets from hour 9, next date time 2015-01-16 10:00:35\n",
      "Finished processing 352 tweets from hour 10, next date time 2015-01-16 11:00:28\n",
      "Finished processing 459 tweets from hour 11, next date time 2015-01-16 12:00:00\n",
      "Finished processing 494 tweets from hour 12, next date time 2015-01-16 13:00:00\n",
      "Finished processing 382 tweets from hour 13, next date time 2015-01-16 14:00:03\n",
      "Finished processing 409 tweets from hour 14, next date time 2015-01-16 15:00:03\n",
      "Finished processing 383 tweets from hour 15, next date time 2015-01-16 16:00:01\n",
      "Finished processing 278 tweets from hour 16, next date time 2015-01-16 17:00:04\n",
      "Finished processing 424 tweets from hour 17, next date time 2015-01-16 18:00:03\n",
      "Finished processing 440 tweets from hour 18, next date time 2015-01-16 19:00:09\n",
      "Finished processing 261 tweets from hour 19, next date time 2015-01-16 20:00:07\n",
      "Finished processing 228 tweets from hour 20, next date time 2015-01-16 21:00:02\n",
      "Finished processing 207 tweets from hour 21, next date time 2015-01-16 22:00:35\n",
      "Finished processing 161 tweets from hour 22, next date time 2015-01-16 23:00:08\n",
      "Finished processing 109 tweets from hour 23, next date time 2015-01-17 00:00:28\n",
      "Finished processing 60 tweets from hour 0, next date time 2015-01-17 01:00:03\n",
      "Finished processing 39 tweets from hour 1, next date time 2015-01-17 02:00:48\n",
      "Finished processing 15 tweets from hour 2, next date time 2015-01-17 03:04:43\n",
      "Finished processing 19 tweets from hour 3, next date time 2015-01-17 04:01:54\n",
      "Finished processing 20 tweets from hour 4, next date time 2015-01-17 05:03:35\n",
      "Finished processing 16 tweets from hour 5, next date time 2015-01-17 06:04:36\n",
      "Finished processing 50 tweets from hour 6, next date time 2015-01-17 07:00:41\n",
      "Finished processing 118 tweets from hour 7, next date time 2015-01-17 08:00:12\n",
      "Finished processing 206 tweets from hour 8, next date time 2015-01-17 09:00:23\n",
      "Finished processing 258 tweets from hour 9, next date time 2015-01-17 10:00:01\n",
      "Finished processing 174 tweets from hour 10, next date time 2015-01-17 11:00:11\n",
      "Finished processing 392 tweets from hour 11, next date time 2015-01-17 12:00:03\n",
      "Finished processing 388 tweets from hour 12, next date time 2015-01-17 13:00:01\n",
      "Finished processing 352 tweets from hour 13, next date time 2015-01-17 14:01:01\n",
      "Finished processing 301 tweets from hour 14, next date time 2015-01-17 15:00:23\n",
      "Finished processing 297 tweets from hour 15, next date time 2015-01-17 16:00:02\n",
      "Finished processing 198 tweets from hour 16, next date time 2015-01-17 17:00:15\n",
      "Finished processing 337 tweets from hour 17, next date time 2015-01-17 18:00:01\n",
      "Finished processing 287 tweets from hour 18, next date time 2015-01-17 19:00:02\n",
      "Finished processing 392 tweets from hour 19, next date time 2015-01-17 20:00:26\n",
      "Finished processing 295 tweets from hour 20, next date time 2015-01-17 21:00:05\n",
      "Finished processing 309 tweets from hour 21, next date time 2015-01-17 22:00:09\n",
      "Finished processing 346 tweets from hour 22, next date time 2015-01-17 23:00:07\n",
      "Finished processing 279 tweets from hour 23, next date time 2015-01-18 00:00:00\n",
      "Finished processing 304 tweets from hour 0, next date time 2015-01-18 01:00:25\n",
      "Finished processing 139 tweets from hour 1, next date time 2015-01-18 02:00:02\n",
      "Finished processing 74 tweets from hour 2, next date time 2015-01-18 03:15:29\n",
      "Finished processing 4 tweets from hour 3, next date time 2015-01-18 04:08:27\n",
      "Finished processing 80 tweets from hour 4, next date time 2015-01-18 05:00:02\n",
      "Finished processing 146 tweets from hour 5, next date time 2015-01-18 06:00:02\n",
      "Finished processing 369 tweets from hour 6, next date time 2015-01-18 07:00:01\n",
      "Finished processing 878 tweets from hour 7, next date time 2015-01-18 08:00:03\n",
      "Finished processing 1231 tweets from hour 8, next date time 2015-01-18 09:00:00\n",
      "Finished processing 1636 tweets from hour 9, next date time 2015-01-18 10:00:01\n",
      "Finished processing 1481 tweets from hour 10, next date time 2015-01-18 11:00:01\n",
      "Finished processing 4059 tweets from hour 11, next date time 2015-01-18 12:00:00\n",
      "Finished processing 7474 tweets from hour 12, next date time 2015-01-18 13:00:02\n",
      "Finished processing 4291 tweets from hour 13, next date time 2015-01-18 14:00:00\n",
      "Finished processing 4881 tweets from hour 14, next date time 2015-01-18 15:00:06\n",
      "Finished processing 20755 tweets from hour 15, next date time 2015-01-18 16:00:01\n",
      "Finished processing 4046 tweets from hour 16, next date time 2015-01-18 17:00:01\n",
      "Finished processing 1793 tweets from hour 17, next date time 2015-01-18 18:00:00\n",
      "Finished processing 1647 tweets from hour 18, next date time 2015-01-18 19:00:00\n",
      "Finished processing 1461 tweets from hour 19, next date time 2015-01-18 20:00:01\n",
      "Finished processing 1064 tweets from hour 20, next date time 2015-01-18 21:00:06\n",
      "Finished processing 785 tweets from hour 21, next date time 2015-01-18 22:00:00\n",
      "Finished processing 632 tweets from hour 22, next date time 2015-01-18 23:00:12\n",
      "Finished processing 389 tweets from hour 23, next date time 2015-01-19 00:00:08\n",
      "Finished processing 246 tweets from hour 0, next date time 2015-01-19 01:00:29\n",
      "Finished processing 150 tweets from hour 1, next date time 2015-01-19 02:00:11\n",
      "Finished processing 83 tweets from hour 2, next date time 2015-01-19 03:00:00\n",
      "Finished processing 93 tweets from hour 3, next date time 2015-01-19 04:00:00\n",
      "Finished processing 100 tweets from hour 4, next date time 2015-01-19 05:00:01\n",
      "Finished processing 103 tweets from hour 5, next date time 2015-01-19 06:00:38\n",
      "Finished processing 193 tweets from hour 6, next date time 2015-01-19 07:00:03\n",
      "Finished processing 311 tweets from hour 7, next date time 2015-01-19 08:00:15\n",
      "Finished processing 416 tweets from hour 8, next date time 2015-01-19 09:00:20\n",
      "Finished processing 479 tweets from hour 9, next date time 2015-01-19 10:00:02\n",
      "Finished processing 267 tweets from hour 10, next date time 2015-01-19 11:00:09\n",
      "Finished processing 414 tweets from hour 11, next date time 2015-01-19 12:00:00\n",
      "Finished processing 392 tweets from hour 12, next date time 2015-01-19 13:00:05\n",
      "Finished processing 372 tweets from hour 13, next date time 2015-01-19 14:00:09\n",
      "Finished processing 282 tweets from hour 14, next date time 2015-01-19 15:00:00\n",
      "Finished processing 287 tweets from hour 15, next date time 2015-01-19 16:00:00\n",
      "Finished processing 145 tweets from hour 16, next date time 2015-01-19 17:00:01\n",
      "Finished processing 216 tweets from hour 17, next date time 2015-01-19 18:00:08\n",
      "Finished processing 231 tweets from hour 18, next date time 2015-01-19 19:00:29\n",
      "Finished processing 241 tweets from hour 19, next date time 2015-01-19 20:00:09\n",
      "Finished processing 218 tweets from hour 20, next date time 2015-01-19 21:00:04\n",
      "Finished processing 243 tweets from hour 21, next date time 2015-01-19 22:00:41\n",
      "Finished processing 152 tweets from hour 22, next date time 2015-01-19 23:00:17\n",
      "Finished processing 136 tweets from hour 23, next date time 2015-01-20 00:00:04\n",
      "Finished processing 90 tweets from hour 0, next date time 2015-01-20 01:00:10\n",
      "Finished processing 38 tweets from hour 1, next date time 2015-01-20 02:00:18\n",
      "Finished processing 29 tweets from hour 2, next date time 2015-01-20 03:00:16\n",
      "Finished processing 22 tweets from hour 3, next date time 2015-01-20 04:00:35\n",
      "Finished processing 27 tweets from hour 4, next date time 2015-01-20 05:00:03\n",
      "Finished processing 31 tweets from hour 5, next date time 2015-01-20 06:01:27\n",
      "Finished processing 84 tweets from hour 6, next date time 2015-01-20 07:00:16\n",
      "Finished processing 125 tweets from hour 7, next date time 2015-01-20 08:00:37\n",
      "Finished processing 171 tweets from hour 8, next date time 2015-01-20 09:00:34\n",
      "Finished processing 198 tweets from hour 9, next date time 2015-01-20 10:01:10\n",
      "Finished processing 109 tweets from hour 10, next date time 2015-01-20 11:00:47\n",
      "Finished processing 179 tweets from hour 11, next date time 2015-01-20 12:22:43\n",
      "Finished processing 6 tweets from hour 12, next date time 2015-01-20 13:04:01\n",
      "Finished processing 23 tweets from hour 13, next date time 2015-01-20 14:04:42\n",
      "Finished processing 151 tweets from hour 14, next date time 2015-01-20 15:00:08\n",
      "Finished processing 182 tweets from hour 15, next date time 2015-01-20 16:00:24\n",
      "Finished processing 116 tweets from hour 16, next date time 2015-01-20 17:00:26\n",
      "Finished processing 243 tweets from hour 17, next date time 2015-01-20 18:00:04\n",
      "Finished processing 317 tweets from hour 18, next date time 2015-01-20 19:00:00\n",
      "Finished processing 260 tweets from hour 19, next date time 2015-01-20 20:00:08\n",
      "Finished processing 292 tweets from hour 20, next date time 2015-01-20 21:00:19\n",
      "Finished processing 222 tweets from hour 21, next date time 2015-01-20 22:00:18\n",
      "Finished processing 171 tweets from hour 22, next date time 2015-01-20 23:00:15\n",
      "Finished processing 103 tweets from hour 23, next date time 2015-01-21 00:01:08\n",
      "Finished processing 46 tweets from hour 0, next date time 2015-01-21 01:01:11\n",
      "Finished processing 18 tweets from hour 1, next date time 2015-01-21 02:01:33\n",
      "Finished processing 27 tweets from hour 2, next date time 2015-01-21 03:01:07\n",
      "Finished processing 27 tweets from hour 3, next date time 2015-01-21 04:01:42\n",
      "Finished processing 25 tweets from hour 4, next date time 2015-01-21 05:01:27\n",
      "Finished processing 28 tweets from hour 5, next date time 2015-01-21 06:00:16\n",
      "Finished processing 55 tweets from hour 6, next date time 2015-01-21 07:00:02\n",
      "Finished processing 75 tweets from hour 7, next date time 2015-01-21 08:00:45\n",
      "Finished processing 78 tweets from hour 8, next date time 2015-01-21 09:00:05\n",
      "Finished processing 93 tweets from hour 9, next date time 2015-01-21 10:00:30\n",
      "Finished processing 91 tweets from hour 10, next date time 2015-01-21 11:00:06\n",
      "Finished processing 102 tweets from hour 11, next date time 2015-01-21 12:00:56\n",
      "Finished processing 130 tweets from hour 12, next date time 2015-01-21 13:00:02\n",
      "Finished processing 90 tweets from hour 13, next date time 2015-01-21 14:00:15\n",
      "Finished processing 93 tweets from hour 14, next date time 2015-01-21 15:00:11\n",
      "Finished processing 138 tweets from hour 15, next date time 2015-01-21 16:00:16\n",
      "Finished processing 182 tweets from hour 16, next date time 2015-01-21 17:00:05\n",
      "Finished processing 192 tweets from hour 17, next date time 2015-01-21 18:00:19\n",
      "Finished processing 209 tweets from hour 18, next date time 2015-01-21 19:02:48\n",
      "Finished processing 212 tweets from hour 19, next date time 2015-01-21 20:01:16\n",
      "Finished processing 170 tweets from hour 20, next date time 2015-01-21 21:00:02\n",
      "Finished processing 139 tweets from hour 21, next date time 2015-01-21 22:00:38\n",
      "Finished processing 84 tweets from hour 22, next date time 2015-01-21 23:01:42\n",
      "Finished processing 79 tweets from hour 23, next date time 2015-01-22 00:00:58\n",
      "Finished processing 29 tweets from hour 0, next date time 2015-01-22 01:00:05\n",
      "Finished processing 18 tweets from hour 1, next date time 2015-01-22 02:01:13\n",
      "Finished processing 14 tweets from hour 2, next date time 2015-01-22 03:00:23\n",
      "Finished processing 15 tweets from hour 3, next date time 2015-01-22 04:02:25\n",
      "Finished processing 15 tweets from hour 4, next date time 2015-01-22 05:02:50\n",
      "Finished processing 21 tweets from hour 5, next date time 2015-01-22 06:00:00\n",
      "Finished processing 59 tweets from hour 6, next date time 2015-01-22 07:01:08\n",
      "Finished processing 90 tweets from hour 7, next date time 2015-01-22 08:00:16\n",
      "Finished processing 144 tweets from hour 8, next date time 2015-01-22 09:01:06\n",
      "Finished processing 165 tweets from hour 9, next date time 2015-01-22 10:00:30\n",
      "Finished processing 97 tweets from hour 10, next date time 2015-01-22 11:00:35\n",
      "Finished processing 76 tweets from hour 11, next date time 2015-01-22 12:01:50\n",
      "Finished processing 77 tweets from hour 12, next date time 2015-01-22 13:20:20\n",
      "Finished processing 8 tweets from hour 13, next date time 2015-01-22 14:19:05\n",
      "Finished processing 12 tweets from hour 14, next date time 2015-01-22 15:03:03\n",
      "Finished processing 14 tweets from hour 15, next date time 2015-01-22 16:18:40\n",
      "Finished processing 82 tweets from hour 16, next date time 2015-01-22 17:00:34\n",
      "Finished processing 169 tweets from hour 17, next date time 2015-01-22 18:00:16\n",
      "Finished processing 165 tweets from hour 18, next date time 2015-01-22 19:00:04\n",
      "Finished processing 187 tweets from hour 19, next date time 2015-01-22 20:00:06\n",
      "Finished processing 201 tweets from hour 20, next date time 2015-01-22 21:00:06\n",
      "Finished processing 207 tweets from hour 21, next date time 2015-01-22 22:00:06\n",
      "Finished processing 149 tweets from hour 22, next date time 2015-01-22 23:00:34\n",
      "Finished processing 76 tweets from hour 23, next date time 2015-01-23 00:00:41\n",
      "Finished processing 46 tweets from hour 0, next date time 2015-01-23 01:00:04\n",
      "Finished processing 23 tweets from hour 1, next date time 2015-01-23 02:00:08\n",
      "Finished processing 19 tweets from hour 2, next date time 2015-01-23 03:03:22\n",
      "Finished processing 17 tweets from hour 3, next date time 2015-01-23 04:04:58\n",
      "Finished processing 24 tweets from hour 4, next date time 2015-01-23 05:00:34\n",
      "Finished processing 32 tweets from hour 5, next date time 2015-01-23 06:01:04\n",
      "Finished processing 111 tweets from hour 6, next date time 2015-01-23 07:00:01\n",
      "Finished processing 162 tweets from hour 7, next date time 2015-01-23 08:00:01\n",
      "Finished processing 206 tweets from hour 8, next date time 2015-01-23 09:00:22\n",
      "Finished processing 135 tweets from hour 9, next date time 2015-01-23 10:00:02\n",
      "Finished processing 220 tweets from hour 10, next date time 2015-01-23 11:00:03\n",
      "Finished processing 206 tweets from hour 11, next date time 2015-01-23 12:00:25\n",
      "Finished processing 208 tweets from hour 12, next date time 2015-01-23 13:00:05\n",
      "Finished processing 204 tweets from hour 13, next date time 2015-01-23 14:00:15\n",
      "Finished processing 217 tweets from hour 14, next date time 2015-01-23 15:00:04\n",
      "Finished processing 170 tweets from hour 15, next date time 2015-01-23 16:00:02\n",
      "Finished processing 331 tweets from hour 16, next date time 2015-01-23 17:00:04\n",
      "Finished processing 264 tweets from hour 17, next date time 2015-01-23 18:00:44\n",
      "Finished processing 336 tweets from hour 18, next date time 2015-01-23 19:00:29\n",
      "Finished processing 201 tweets from hour 19, next date time 2015-01-23 20:01:26\n",
      "Finished processing 155 tweets from hour 20, next date time 2015-01-23 21:00:27\n",
      "Finished processing 128 tweets from hour 21, next date time 2015-01-23 22:00:07\n",
      "Finished processing 101 tweets from hour 22, next date time 2015-01-23 23:01:15\n",
      "Finished processing 68 tweets from hour 23, next date time 2015-01-24 00:00:27\n",
      "Finished processing 38 tweets from hour 0, next date time 2015-01-24 01:00:32\n",
      "Finished processing 33 tweets from hour 1, next date time 2015-01-24 02:02:49\n",
      "Finished processing 54 tweets from hour 2, next date time 2015-01-24 03:00:48\n",
      "Finished processing 16 tweets from hour 3, next date time 2015-01-24 04:01:34\n",
      "Finished processing 5 tweets from hour 4, next date time 2015-01-24 05:01:09\n",
      "Finished processing 38 tweets from hour 5, next date time 2015-01-24 06:00:24\n",
      "Finished processing 55 tweets from hour 6, next date time 2015-01-24 07:00:35\n",
      "Finished processing 81 tweets from hour 7, next date time 2015-01-24 08:00:42\n",
      "Finished processing 134 tweets from hour 8, next date time 2015-01-24 09:00:26\n",
      "Finished processing 146 tweets from hour 9, next date time 2015-01-24 10:00:46\n",
      "Finished processing 198 tweets from hour 10, next date time 2015-01-24 11:00:15\n",
      "Finished processing 188 tweets from hour 11, next date time 2015-01-24 12:00:17\n",
      "Finished processing 318 tweets from hour 12, next date time 2015-01-24 13:00:08\n",
      "Finished processing 176 tweets from hour 13, next date time 2015-01-24 14:00:05\n",
      "Finished processing 174 tweets from hour 14, next date time 2015-01-24 15:01:18\n",
      "Finished processing 122 tweets from hour 15, next date time 2015-01-24 16:00:05\n",
      "Finished processing 139 tweets from hour 16, next date time 2015-01-24 17:00:34\n",
      "Finished processing 150 tweets from hour 17, next date time 2015-01-24 18:01:19\n",
      "Finished processing 156 tweets from hour 18, next date time 2015-01-24 19:00:01\n",
      "Finished processing 164 tweets from hour 19, next date time 2015-01-24 20:00:08\n",
      "Finished processing 157 tweets from hour 20, next date time 2015-01-24 21:00:58\n",
      "Finished processing 163 tweets from hour 21, next date time 2015-01-24 22:01:01\n",
      "Finished processing 103 tweets from hour 22, next date time 2015-01-24 23:00:03\n",
      "Finished processing 66 tweets from hour 23, next date time 2015-01-25 00:00:56\n",
      "Finished processing 31 tweets from hour 0, next date time 2015-01-25 01:00:34\n",
      "Finished processing 31 tweets from hour 1, next date time 2015-01-25 02:05:07\n",
      "Finished processing 17 tweets from hour 2, next date time 2015-01-25 03:00:23\n",
      "Finished processing 22 tweets from hour 3, next date time 2015-01-25 04:00:00\n",
      "Finished processing 18 tweets from hour 4, next date time 2015-01-25 05:00:57\n",
      "Finished processing 27 tweets from hour 5, next date time 2015-01-25 06:00:11\n",
      "Finished processing 43 tweets from hour 6, next date time 2015-01-25 07:01:00\n",
      "Finished processing 123 tweets from hour 7, next date time 2015-01-25 08:00:07\n",
      "Finished processing 296 tweets from hour 8, next date time 2015-01-25 09:00:11\n",
      "Finished processing 453 tweets from hour 9, next date time 2015-01-25 10:00:00\n",
      "Finished processing 738 tweets from hour 10, next date time 2015-01-25 11:00:00\n",
      "Finished processing 402 tweets from hour 11, next date time 2015-01-25 12:00:05\n",
      "Finished processing 303 tweets from hour 12, next date time 2015-01-25 13:00:07\n",
      "Finished processing 326 tweets from hour 13, next date time 2015-01-25 14:00:01\n",
      "Finished processing 283 tweets from hour 14, next date time 2015-01-25 15:00:45\n",
      "Finished processing 262 tweets from hour 15, next date time 2015-01-25 16:00:06\n",
      "Finished processing 204 tweets from hour 16, next date time 2015-01-25 17:00:00\n",
      "Finished processing 306 tweets from hour 17, next date time 2015-01-25 18:00:03\n",
      "Finished processing 279 tweets from hour 18, next date time 2015-01-25 19:00:04\n",
      "Finished processing 221 tweets from hour 19, next date time 2015-01-25 20:00:12\n",
      "Finished processing 173 tweets from hour 20, next date time 2015-01-25 21:00:16\n",
      "Finished processing 173 tweets from hour 21, next date time 2015-01-25 22:00:08\n",
      "Finished processing 119 tweets from hour 22, next date time 2015-01-25 23:00:33\n",
      "Finished processing 68 tweets from hour 23, next date time 2015-01-26 00:00:11\n",
      "Finished processing 44 tweets from hour 0, next date time 2015-01-26 01:03:52\n",
      "Finished processing 6 tweets from hour 1, next date time 2015-01-26 02:04:13\n",
      "Finished processing 85 tweets from hour 2, next date time 2015-01-26 03:02:26\n",
      "Finished processing 22 tweets from hour 3, next date time 2015-01-26 04:03:48\n",
      "Finished processing 19 tweets from hour 4, next date time 2015-01-26 05:03:32\n",
      "Finished processing 34 tweets from hour 5, next date time 2015-01-26 06:00:37\n",
      "Finished processing 67 tweets from hour 6, next date time 2015-01-26 07:00:46\n",
      "Finished processing 130 tweets from hour 7, next date time 2015-01-26 08:00:36\n",
      "Finished processing 208 tweets from hour 8, next date time 2015-01-26 09:00:04\n",
      "Finished processing 183 tweets from hour 9, next date time 2015-01-26 10:00:35\n",
      "Finished processing 202 tweets from hour 10, next date time 2015-01-26 11:00:00\n",
      "Finished processing 217 tweets from hour 11, next date time 2015-01-26 12:00:13\n",
      "Finished processing 161 tweets from hour 12, next date time 2015-01-26 13:00:05\n",
      "Finished processing 157 tweets from hour 13, next date time 2015-01-26 14:00:08\n",
      "Finished processing 236 tweets from hour 14, next date time 2015-01-26 15:00:06\n",
      "Finished processing 151 tweets from hour 15, next date time 2015-01-26 16:00:03\n",
      "Finished processing 164 tweets from hour 16, next date time 2015-01-26 17:00:00\n",
      "Finished processing 187 tweets from hour 17, next date time 2015-01-26 18:00:22\n",
      "Finished processing 215 tweets from hour 18, next date time 2015-01-26 19:00:03\n",
      "Finished processing 296 tweets from hour 19, next date time 2015-01-26 20:00:04\n",
      "Finished processing 387 tweets from hour 20, next date time 2015-01-26 21:00:10\n",
      "Finished processing 238 tweets from hour 21, next date time 2015-01-26 22:00:15\n",
      "Finished processing 209 tweets from hour 22, next date time 2015-01-26 23:00:41\n",
      "Finished processing 105 tweets from hour 23, next date time 2015-01-27 00:00:59\n",
      "Finished processing 42 tweets from hour 0, next date time 2015-01-27 01:00:20\n",
      "Finished processing 30 tweets from hour 1, next date time 2015-01-27 02:01:42\n",
      "Finished processing 28 tweets from hour 2, next date time 2015-01-27 03:04:40\n",
      "Finished processing 23 tweets from hour 3, next date time 2015-01-27 04:02:12\n",
      "Finished processing 49 tweets from hour 4, next date time 2015-01-27 05:00:37\n",
      "Finished processing 92 tweets from hour 5, next date time 2015-01-27 06:00:13\n",
      "Finished processing 99 tweets from hour 6, next date time 2015-01-27 07:00:04\n",
      "Finished processing 167 tweets from hour 7, next date time 2015-01-27 08:00:18\n",
      "Finished processing 222 tweets from hour 8, next date time 2015-01-27 09:00:23\n",
      "Finished processing 359 tweets from hour 9, next date time 2015-01-27 10:00:14\n",
      "Finished processing 395 tweets from hour 10, next date time 2015-01-27 11:00:02\n",
      "Finished processing 870 tweets from hour 11, next date time 2015-01-27 12:00:00\n",
      "Finished processing 593 tweets from hour 12, next date time 2015-01-27 13:00:01\n",
      "Finished processing 336 tweets from hour 13, next date time 2015-01-27 14:00:10\n",
      "Finished processing 317 tweets from hour 14, next date time 2015-01-27 15:00:08\n",
      "Finished processing 297 tweets from hour 15, next date time 2015-01-27 16:00:27\n",
      "Finished processing 230 tweets from hour 16, next date time 2015-01-27 17:00:02\n",
      "Finished processing 266 tweets from hour 17, next date time 2015-01-27 18:00:07\n",
      "Finished processing 238 tweets from hour 18, next date time 2015-01-27 19:00:02\n",
      "Finished processing 263 tweets from hour 19, next date time 2015-01-27 20:00:01\n",
      "Finished processing 312 tweets from hour 20, next date time 2015-01-27 21:00:28\n",
      "Finished processing 234 tweets from hour 21, next date time 2015-01-27 22:00:28\n",
      "Finished processing 172 tweets from hour 22, next date time 2015-01-27 23:00:47\n",
      "Finished processing 111 tweets from hour 23, next date time 2015-01-28 00:00:10\n",
      "Finished processing 45 tweets from hour 0, next date time 2015-01-28 01:02:02\n",
      "Finished processing 38 tweets from hour 1, next date time 2015-01-28 02:03:52\n",
      "Finished processing 19 tweets from hour 2, next date time 2015-01-28 03:03:04\n",
      "Finished processing 31 tweets from hour 3, next date time 2015-01-28 04:00:39\n",
      "Finished processing 38 tweets from hour 4, next date time 2015-01-28 05:00:58\n",
      "Finished processing 38 tweets from hour 5, next date time 2015-01-28 06:00:41\n",
      "Finished processing 85 tweets from hour 6, next date time 2015-01-28 07:00:10\n",
      "Finished processing 162 tweets from hour 7, next date time 2015-01-28 08:00:12\n",
      "Finished processing 232 tweets from hour 8, next date time 2015-01-28 09:00:02\n",
      "Finished processing 313 tweets from hour 9, next date time 2015-01-28 10:00:08\n",
      "Finished processing 327 tweets from hour 10, next date time 2015-01-28 11:00:01\n",
      "Finished processing 287 tweets from hour 11, next date time 2015-01-28 12:00:01\n",
      "Finished processing 262 tweets from hour 12, next date time 2015-01-28 13:00:06\n",
      "Finished processing 260 tweets from hour 13, next date time 2015-01-28 14:00:03\n",
      "Finished processing 288 tweets from hour 14, next date time 2015-01-28 15:00:03\n",
      "Finished processing 238 tweets from hour 15, next date time 2015-01-28 16:00:00\n",
      "Finished processing 243 tweets from hour 16, next date time 2015-01-28 17:00:00\n",
      "Finished processing 287 tweets from hour 17, next date time 2015-01-28 18:00:12\n",
      "Finished processing 249 tweets from hour 18, next date time 2015-01-28 19:00:00\n",
      "Finished processing 351 tweets from hour 19, next date time 2015-01-28 20:00:01\n",
      "Finished processing 89 tweets from hour 20, next date time 2015-01-28 21:02:03\n",
      "Finished processing 11 tweets from hour 21, next date time 2015-01-28 22:00:01\n",
      "Finished processing 11 tweets from hour 22, next date time 2015-01-28 23:10:33\n",
      "Finished processing 7 tweets from hour 23, next date time 2015-01-29 00:15:33\n",
      "Finished processing 18 tweets from hour 0, next date time 2015-01-29 01:06:25\n",
      "Finished processing 12 tweets from hour 1, next date time 2015-01-29 02:19:22\n",
      "Finished processing 6 tweets from hour 2, next date time 2015-01-29 03:06:23\n",
      "Finished processing 6 tweets from hour 3, next date time 2015-01-29 04:06:46\n",
      "Finished processing 5 tweets from hour 4, next date time 2015-01-29 05:00:06\n",
      "Finished processing 24 tweets from hour 5, next date time 2015-01-29 06:02:38\n",
      "Finished processing 29 tweets from hour 6, next date time 2015-01-29 07:01:41\n",
      "Finished processing 35 tweets from hour 7, next date time 2015-01-29 08:00:21\n",
      "Finished processing 58 tweets from hour 8, next date time 2015-01-29 09:00:15\n",
      "Finished processing 86 tweets from hour 9, next date time 2015-01-29 10:00:00\n",
      "Finished processing 60 tweets from hour 10, next date time 2015-01-29 11:02:02\n",
      "Finished processing 37 tweets from hour 11, next date time 2015-01-29 12:00:00\n",
      "Finished processing 38 tweets from hour 12, next date time 2015-01-29 13:04:06\n",
      "Finished processing 46 tweets from hour 13, next date time 2015-01-29 14:00:12\n",
      "Finished processing 50 tweets from hour 14, next date time 2015-01-29 15:01:09\n",
      "Finished processing 34 tweets from hour 15, next date time 2015-01-29 16:02:41\n",
      "Finished processing 67 tweets from hour 16, next date time 2015-01-29 17:00:10\n",
      "Finished processing 51 tweets from hour 17, next date time 2015-01-29 18:01:25\n",
      "Finished processing 26 tweets from hour 18, next date time 2015-01-29 19:01:38\n",
      "Finished processing 53 tweets from hour 19, next date time 2015-01-29 20:01:10\n",
      "Finished processing 21 tweets from hour 20, next date time 2015-01-29 21:32:04\n",
      "Finished processing 17 tweets from hour 21, next date time 2015-01-29 22:01:26\n",
      "Finished processing 41 tweets from hour 22, next date time 2015-01-29 23:01:25\n",
      "Finished processing 30 tweets from hour 23, next date time 2015-01-30 00:00:05\n",
      "Finished processing 16 tweets from hour 0, next date time 2015-01-30 01:01:04\n",
      "Finished processing 11 tweets from hour 1, next date time 2015-01-30 02:12:17\n",
      "Finished processing 12 tweets from hour 2, next date time 2015-01-30 03:01:55\n",
      "Finished processing 21 tweets from hour 3, next date time 2015-01-30 04:19:40\n",
      "Finished processing 10 tweets from hour 4, next date time 2015-01-30 05:00:09\n",
      "Finished processing 7 tweets from hour 5, next date time 2015-01-30 06:11:00\n",
      "Finished processing 19 tweets from hour 6, next date time 2015-01-30 07:00:09\n",
      "Finished processing 105 tweets from hour 7, next date time 2015-01-30 08:00:27\n",
      "Finished processing 162 tweets from hour 8, next date time 2015-01-30 09:01:05\n",
      "Finished processing 99 tweets from hour 9, next date time 2015-01-30 10:00:42\n",
      "Finished processing 156 tweets from hour 10, next date time 2015-01-30 11:00:03\n",
      "Finished processing 199 tweets from hour 11, next date time 2015-01-30 12:00:05\n",
      "Finished processing 223 tweets from hour 12, next date time 2015-01-30 13:00:04\n",
      "Finished processing 154 tweets from hour 13, next date time 2015-01-30 14:00:05\n",
      "Finished processing 193 tweets from hour 14, next date time 2015-01-30 15:00:58\n",
      "Finished processing 102 tweets from hour 15, next date time 2015-01-30 16:00:25\n",
      "Finished processing 49 tweets from hour 16, next date time 2015-01-30 17:00:55\n",
      "Finished processing 18 tweets from hour 17, next date time 2015-01-30 18:05:41\n",
      "Finished processing 32 tweets from hour 18, next date time 2015-01-30 19:00:28\n",
      "Finished processing 13 tweets from hour 19, next date time 2015-01-30 20:10:59\n",
      "Finished processing 13 tweets from hour 20, next date time 2015-01-30 21:00:00\n",
      "Finished processing 15 tweets from hour 21, next date time 2015-01-30 22:01:17\n",
      "Finished processing 14 tweets from hour 22, next date time 2015-01-30 23:00:46\n",
      "Finished processing 10 tweets from hour 23, next date time 2015-01-31 00:01:14\n",
      "Finished processing 3 tweets from hour 0, next date time 2015-01-31 01:09:45\n",
      "Finished processing 19 tweets from hour 1, next date time 2015-01-31 02:19:18\n",
      "Finished processing 1 tweets from hour 2, next date time 2015-01-31 03:45:42\n",
      "Finished processing 3 tweets from hour 3, next date time 2015-01-31 04:09:26\n",
      "Finished processing 5 tweets from hour 4, next date time 2015-01-31 05:07:57\n",
      "Finished processing 6 tweets from hour 5, next date time 2015-01-31 06:08:56\n",
      "Finished processing 7 tweets from hour 6, next date time 2015-01-31 07:06:06\n",
      "Finished processing 12 tweets from hour 7, next date time 2015-01-31 08:00:05\n",
      "Finished processing 25 tweets from hour 8, next date time 2015-01-31 09:05:30\n",
      "Finished processing 35 tweets from hour 9, next date time 2015-01-31 10:00:14\n",
      "Finished processing 36 tweets from hour 10, next date time 2015-01-31 11:00:17\n",
      "Finished processing 34 tweets from hour 11, next date time 2015-01-31 12:00:10\n",
      "Finished processing 60 tweets from hour 12, next date time 2015-01-31 13:00:28\n",
      "Finished processing 51 tweets from hour 13, next date time 2015-01-31 14:01:09\n",
      "Finished processing 62 tweets from hour 14, next date time 2015-01-31 15:01:24\n",
      "Finished processing 51 tweets from hour 15, next date time 2015-01-31 16:01:33\n",
      "Finished processing 133 tweets from hour 16, next date time 2015-01-31 17:00:09\n",
      "Finished processing 143 tweets from hour 17, next date time 2015-01-31 18:01:12\n",
      "Finished processing 150 tweets from hour 18, next date time 2015-01-31 19:00:04\n",
      "Finished processing 75 tweets from hour 19, next date time 2015-01-31 20:00:13\n",
      "Finished processing 158 tweets from hour 20, next date time 2015-01-31 21:00:18\n",
      "Finished processing 143 tweets from hour 21, next date time 2015-01-31 22:00:09\n",
      "Finished processing 136 tweets from hour 22, next date time 2015-01-31 23:00:18\n",
      "Finished processing 114 tweets from hour 23, next date time 2015-02-01 00:00:07\n",
      "Finished processing 112 tweets from hour 0, next date time 2015-02-01 01:00:05\n",
      "Finished processing 96 tweets from hour 1, next date time 2015-02-01 02:00:10\n",
      "Finished processing 55 tweets from hour 2, next date time 2015-02-01 03:01:07\n",
      "Finished processing 66 tweets from hour 3, next date time 2015-02-01 04:00:29\n",
      "Finished processing 54 tweets from hour 4, next date time 2015-02-01 05:00:21\n",
      "Finished processing 116 tweets from hour 5, next date time 2015-02-01 06:00:10\n",
      "Finished processing 194 tweets from hour 6, next date time 2015-02-01 07:00:12\n",
      "Finished processing 308 tweets from hour 7, next date time 2015-02-01 08:00:00\n",
      "Finished processing 274 tweets from hour 8, next date time 2015-02-01 09:00:03\n",
      "Finished processing 464 tweets from hour 9, next date time 2015-02-01 10:00:00\n",
      "Finished processing 3047 tweets from hour 10, next date time 2015-02-01 11:00:00\n",
      "Finished processing 3147 tweets from hour 11, next date time 2015-02-01 12:00:02\n",
      "Finished processing 3782 tweets from hour 12, next date time 2015-02-01 13:00:00\n",
      "Finished processing 3948 tweets from hour 13, next date time 2015-02-01 14:00:01\n",
      "Finished processing 5398 tweets from hour 14, next date time 2015-02-01 15:00:00\n",
      "Finished processing 12514 tweets from hour 15, next date time 2015-02-01 16:00:00\n",
      "Finished processing 8847 tweets from hour 16, next date time 2015-02-01 17:00:00\n",
      "Finished processing 10341 tweets from hour 17, next date time 2015-02-01 18:00:00\n",
      "Finished processing 8198 tweets from hour 18, next date time 2015-02-01 19:00:00\n",
      "Finished processing 3822 tweets from hour 19, next date time 2015-02-01 20:00:02\n",
      "Finished processing 980 tweets from hour 20, next date time 2015-02-01 21:00:04\n",
      "Finished processing 599 tweets from hour 21, next date time 2015-02-01 22:00:04\n",
      "Finished processing 746 tweets from hour 22, next date time 2015-02-01 23:00:01\n",
      "Finished processing 384 tweets from hour 23, next date time 2015-02-02 00:00:28\n",
      "Finished processing 165 tweets from hour 0, next date time 2015-02-02 01:00:07\n",
      "Finished processing 115 tweets from hour 1, next date time 2015-02-02 02:00:16\n",
      "Finished processing 86 tweets from hour 2, next date time 2015-02-02 03:02:26\n",
      "Finished processing 102 tweets from hour 3, next date time 2015-02-02 04:01:04\n",
      "Finished processing 127 tweets from hour 4, next date time 2015-02-02 05:00:09\n",
      "Finished processing 150 tweets from hour 5, next date time 2015-02-02 06:00:35\n",
      "Finished processing 163 tweets from hour 6, next date time 2015-02-02 07:00:59\n",
      "Finished processing 256 tweets from hour 7, next date time 2015-02-02 08:00:35\n",
      "Finished processing 282 tweets from hour 8, next date time 2015-02-02 09:00:13\n",
      "Finished processing 468 tweets from hour 9, next date time 2015-02-02 10:00:06\n",
      "Finished processing 389 tweets from hour 10, next date time 2015-02-02 11:01:19\n",
      "Finished processing 45 tweets from hour 11, next date time 2015-02-02 12:01:06\n",
      "Finished processing 39 tweets from hour 12, next date time 2015-02-02 13:00:19\n",
      "Finished processing 26 tweets from hour 13, next date time 2015-02-02 14:01:00\n",
      "Finished processing 30 tweets from hour 14, next date time 2015-02-02 15:00:10\n",
      "Finished processing 36 tweets from hour 15, next date time 2015-02-02 16:00:52\n",
      "Finished processing 26 tweets from hour 16, next date time 2015-02-02 17:01:38\n",
      "Finished processing 24 tweets from hour 17, next date time 2015-02-02 18:01:09\n",
      "Finished processing 22 tweets from hour 18, next date time 2015-02-02 19:05:17\n",
      "Finished processing 13 tweets from hour 19, next date time 2015-02-02 20:01:44\n",
      "Finished processing 20 tweets from hour 20, next date time 2015-02-02 21:01:15\n",
      "Finished processing 12 tweets from hour 21, next date time 2015-02-02 22:03:22\n",
      "Finished processing 15 tweets from hour 22, next date time 2015-02-02 23:00:29\n",
      "Finished processing 4 tweets from hour 23, next date time 2015-02-03 00:02:07\n",
      "Finished processing 2 tweets from hour 0, next date time 2015-02-03 01:42:42\n",
      "Finished processing 1 tweets from hour 1, next date time 2015-02-03 02:53:46\n",
      "Finished processing 2 tweets from hour 2, next date time 2015-02-03 03:29:45\n",
      "Finished processing 1 tweets from hour 3, next date time 2015-02-03 04:30:43\n",
      "Finished processing 1 tweets from hour 4, next date time 2015-02-03 05:18:06\n",
      "Finished processing 2 tweets from hour 5, next date time 2015-02-03 06:16:05\n",
      "Finished processing 4 tweets from hour 6, next date time 2015-02-03 07:00:55\n",
      "Finished processing 14 tweets from hour 7, next date time 2015-02-03 08:01:08\n",
      "Finished processing 8 tweets from hour 8, next date time 2015-02-03 09:24:35\n",
      "Finished processing 6 tweets from hour 9, next date time 2015-02-03 10:08:26\n",
      "Finished processing 11 tweets from hour 10, next date time 2015-02-03 11:00:36\n",
      "Finished processing 14 tweets from hour 11, next date time 2015-02-03 12:01:10\n",
      "Finished processing 18 tweets from hour 12, next date time 2015-02-03 13:03:46\n",
      "Finished processing 16 tweets from hour 13, next date time 2015-02-03 14:01:13\n",
      "Finished processing 3 tweets from hour 14, next date time 2015-02-03 15:00:54\n",
      "Finished processing 9 tweets from hour 15, next date time 2015-02-03 16:04:41\n",
      "Finished processing 9 tweets from hour 16, next date time 2015-02-03 17:29:38\n",
      "Finished processing 4 tweets from hour 17, next date time 2015-02-03 18:00:21\n",
      "Finished processing 3 tweets from hour 18, next date time 2015-02-03 19:00:55\n",
      "Finished processing 2 tweets from hour 19, next date time 2015-02-03 20:07:30\n",
      "Finished processing 7 tweets from hour 20, next date time 2015-02-03 21:05:09\n",
      "Finished processing 3 tweets from hour 21, next date time 2015-02-03 22:06:52\n",
      "Finished processing 3 tweets from hour 22, next date time 2015-02-03 23:31:14\n",
      "Finished processing 2 tweets from hour 23, next date time 2015-02-04 00:27:59\n",
      "Finished processing 3 tweets from hour 0, next date time 2015-02-04 01:03:26\n",
      "Finished processing 4 tweets from hour 1, next date time 2015-02-04 03:01:00\n",
      "Finished processing 1 tweets from hour 3, next date time 2015-02-04 05:16:15\n",
      "Finished processing 3 tweets from hour 5, next date time 2015-02-04 06:41:52\n",
      "Finished processing 3 tweets from hour 6, next date time 2015-02-04 07:16:38\n",
      "Finished processing 4 tweets from hour 7, next date time 2015-02-04 08:44:24\n",
      "Finished processing 5 tweets from hour 8, next date time 2015-02-04 09:04:28\n",
      "Finished processing 4 tweets from hour 9, next date time 2015-02-04 10:00:27\n",
      "Finished processing 6 tweets from hour 10, next date time 2015-02-04 11:01:01\n",
      "Finished processing 4 tweets from hour 11, next date time 2015-02-04 12:01:18\n",
      "Finished processing 5 tweets from hour 12, next date time 2015-02-04 13:01:27\n",
      "Finished processing 3 tweets from hour 13, next date time 2015-02-04 14:01:08\n",
      "Finished processing 6 tweets from hour 14, next date time 2015-02-04 15:08:35\n",
      "Finished processing 8 tweets from hour 15, next date time 2015-02-04 16:06:04\n",
      "Finished processing 8 tweets from hour 16, next date time 2015-02-04 17:19:37\n",
      "Finished processing 7 tweets from hour 17, next date time 2015-02-04 18:12:43\n",
      "Finished processing 8 tweets from hour 18, next date time 2015-02-04 19:29:18\n",
      "Finished processing 7 tweets from hour 19, next date time 2015-02-04 20:00:34\n",
      "Finished processing 2 tweets from hour 20, next date time 2015-02-04 21:08:29\n",
      "Finished processing 2 tweets from hour 21, next date time 2015-02-04 22:31:33\n",
      "Finished processing 2 tweets from hour 22, next date time 2015-02-04 23:04:21\n",
      "Finished processing 1 tweets from hour 23, next date time 2015-02-05 00:06:05\n",
      "Finished processing 1 tweets from hour 0, next date time 2015-02-05 02:46:26\n",
      "Finished processing 1 tweets from hour 2, next date time 2015-02-05 03:38:13\n",
      "Finished processing 1 tweets from hour 3, next date time 2015-02-05 05:00:31\n",
      "Finished processing 2 tweets from hour 5, next date time 2015-02-05 06:12:39\n",
      "Finished processing 1 tweets from hour 6, next date time 2015-02-05 07:39:26\n",
      "Finished processing 2 tweets from hour 7, next date time 2015-02-05 08:00:32\n",
      "Finished processing 8 tweets from hour 8, next date time 2015-02-05 09:00:28\n",
      "Finished processing 6 tweets from hour 9, next date time 2015-02-05 10:36:03\n",
      "Finished processing 4 tweets from hour 10, next date time 2015-02-05 11:10:50\n",
      "Finished processing 6 tweets from hour 11, next date time 2015-02-05 12:02:42\n",
      "Finished processing 7 tweets from hour 12, next date time 2015-02-05 13:01:13\n",
      "Finished processing 7 tweets from hour 13, next date time 2015-02-05 14:38:38\n",
      "Finished processing 1 tweets from hour 14, next date time 2015-02-05 15:00:32\n",
      "Finished processing 4 tweets from hour 15, next date time 2015-02-05 16:04:15\n",
      "Finished processing 3 tweets from hour 16, next date time 2015-02-05 17:25:00\n",
      "Finished processing 3 tweets from hour 17, next date time 2015-02-05 18:02:59\n",
      "Finished processing 4 tweets from hour 18, next date time 2015-02-05 19:05:30\n",
      "Finished processing 2 tweets from hour 19, next date time 2015-02-05 20:14:54\n",
      "Finished processing 3 tweets from hour 20, next date time 2015-02-05 21:10:20\n",
      "Finished processing 8 tweets from hour 21, next date time 2015-02-05 22:31:47\n",
      "Finished processing 2 tweets from hour 22, next date time 2015-02-05 23:46:14\n",
      "Finished processing 2 tweets from hour 23, next date time 2015-02-06 00:04:31\n",
      "Finished processing 2 tweets from hour 0, next date time 2015-02-06 02:19:46\n",
      "Finished processing 2 tweets from hour 2, next date time 2015-02-06 03:16:17\n",
      "Finished processing 1 tweets from hour 3, next date time 2015-02-06 04:15:29\n",
      "Finished processing 2 tweets from hour 4, next date time 2015-02-06 05:10:08\n",
      "Finished processing 1 tweets from hour 5, next date time 2015-02-06 06:43:44\n",
      "Finished processing 1 tweets from hour 6, next date time 2015-02-06 07:24:08\n",
      "Finished processing 2 tweets from hour 7, next date time 2015-02-06 08:36:06\n",
      "Finished processing 4 tweets from hour 8, next date time 2015-02-06 09:04:37\n",
      "Finished processing 5 tweets from hour 9, next date time 2015-02-06 10:04:56\n",
      "Finished processing 4 tweets from hour 10, next date time 2015-02-06 11:04:27\n",
      "Finished processing 6 tweets from hour 11, next date time 2015-02-06 12:01:03\n",
      "Finished processing 9 tweets from hour 12, next date time 2015-02-06 13:52:12\n",
      "Finished processing 1 tweets from hour 13, next date time 2015-02-06 14:00:18\n",
      "Finished processing 3 tweets from hour 14, next date time 2015-02-06 15:15:34\n",
      "Finished processing 6 tweets from hour 15, next date time 2015-02-06 16:03:02\n",
      "Finished processing 1 tweets from hour 16, next date time 2015-02-06 17:01:18\n",
      "Finished processing 1 tweets from hour 17, next date time 2015-02-06 18:23:28\n",
      "Finished processing 2 tweets from hour 18, next date time 2015-02-06 19:08:56\n",
      "Finished processing 2 tweets from hour 19, next date time 2015-02-06 20:03:52\n",
      "Finished processing 4 tweets from hour 20, next date time 2015-02-06 21:15:26\n",
      "Finished processing 1 tweets from hour 21, next date time 2015-02-06 22:01:13\n",
      "Finished processing 4 tweets from hour 22, next date time 2015-02-06 23:54:02\n",
      "Finished processing 2 tweets from hour 23, next date time 2015-02-07 02:17:49\n",
      "Outputting to 'tweets_#gohawks.csv' ...\n",
      "--------------------\n",
      "Total number of tweets 188135\n",
      "Average number of tweets per hour 276.669118\n",
      "Average number of retweets 0.209164\n",
      "Average number of followers of (77168) users 1720.634084\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "import pprint\n",
    "from os import listdir\n",
    "from feature_extract import feature_extract\n",
    "\n",
    "HOUR_INDEX = 3\n",
    "MINUTE_INDEX = 4\n",
    "SECOND_INDEX = 5\n",
    "    \n",
    "files = listdir('../tweet_data')\n",
    "print(files)\n",
    "\n",
    "from os.path import splitext\n",
    "\n",
    "import re\n",
    "\n",
    "for fname in files:\n",
    "    m = re.search('#.+', splitext(files[0])[0])\n",
    "    if m:\n",
    "        hashtag = m.group()\n",
    "        print(\"Processing '%s'\" % hashtag)\n",
    "    outfile = splitext(fname)[0] + '.csv'\n",
    "    print(\"Output file name '%s'\" % outfile)\n",
    "    \n",
    "    f_handle = open('../tweet_data/'+fname, encoding=\"utf8\")\n",
    "    feature_extract(f_handle, outfile)\n",
    "    f_handle.close()\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "HOUR_INDEX = 3\n",
    "MINUTE_INDEX = 4\n",
    "SECOND_INDEX = 5\n",
    "\n",
    "def feature_extract(f, o_file):\n",
    "    import json\n",
    "    import time\n",
    "    from datetime import date\n",
    "\n",
    "    line = f.readline()\n",
    "    tweet = json.loads(line)\n",
    "\n",
    "    n_tweets = 0 # number of tweets per hour\n",
    "    n_followers = {} # uid -> (nfollower, ntweets) per hour\n",
    "    n_retweets = 0 # number of retweets per hour\n",
    "    num_window = 0 # total number of hours\n",
    "\n",
    "    user_follower = {}\n",
    "\n",
    "    # self defined features (for part 2)\n",
    "    # n_users:-  number of users tweeted per hour\n",
    "    # n_users_3:- number of users who tweeted 3 times or more per hour\n",
    "    n_len_100 = 0 # number of tweets with more than 100 characters per hour\n",
    "\n",
    "    # outputs\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"\n",
    "    output: n_tweets  n_retweets  sum_followers  max_followers  hour \\\n",
    "            avg_tweet_per_user  n_users  n_users_3  n_len_100\n",
    "    \"\"\"\n",
    "    output = np.empty([0, 9])\n",
    "\n",
    "    # get start hour from first tweet\n",
    "    start_time = list(time.localtime(tweet['firstpost_date']))\n",
    "    start_time[MINUTE_INDEX] = 0; start_time[SECOND_INDEX] = 0\n",
    "    nth_hour = start_time[HOUR_INDEX]\n",
    "    start_time = time.mktime(start_time)\n",
    "    start_date = date.fromtimestamp(start_time)\n",
    "    print \"Starting from time %s\" % time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time))\n",
    "\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    while len(line) != 0:\n",
    "        tweet = json.loads(line)\n",
    "        line = f.readline()\n",
    "        tweet_time = tweet['firstpost_date']\n",
    "        tweet_hour = time.localtime(tweet_time).tm_hour\n",
    "        if tweet_hour != nth_hour or start_date != date.fromtimestamp(float(tweet_time)):\n",
    "            print \"Finished processing %d tweets from hour %d, next date time %s\" %\\\n",
    "                  (n_tweets, nth_hour, time.strftime(time_format, time.localtime(tweet_time)))\n",
    "            # update output\n",
    "            tweets_per_user = np.array(n_followers.values())[:, 1]\n",
    "            new_hour = np.array([[n_tweets, n_retweets, sum(n_followers), max(n_followers), nth_hour, \\\n",
    "                                  np.mean(tweets_per_user), len(n_followers), sum(tweets_per_user >= 3), \\\n",
    "                                  n_len_100]])\n",
    "            output = np.append(output, new_hour, axis=0)\n",
    "            # clear & update hourly variables\n",
    "            num_window += 1\n",
    "            n_tweets = 0 # number of tweets per hour\n",
    "            n_followers = {} # number of followers of users posting the tweets per hour\n",
    "            n_retweets = 0 # number of retweets per hour\n",
    "            nth_hour = tweet_hour  # hour of the day\n",
    "            n_len_100 = 0\n",
    "\n",
    "        # extract features\n",
    "        n_tweets += 1\n",
    "        n_retweets += tweet['tweet']['retweet_count']\n",
    "        if tweet['tweet']['user']['id'] in n_followers:\n",
    "            # increment user tweet count\n",
    "            tweet_count = n_followers[tweet['tweet']['user']['id']][1] + 1\n",
    "            n_followers[tweet['tweet']['user']['id']] = (tweet['tweet']['user']['followers_count'], tweet_count)\n",
    "        else:\n",
    "            n_followers[tweet['tweet']['user']['id']] = (tweet['tweet']['user']['followers_count'], 1)\n",
    "        if (len(tweet['tweet']['text']) >= 100): n_len_100 += 1\n",
    "        user_follower[tweet['tweet']['user']['id']] = tweet['tweet']['user']['followers_count']\n",
    "        start_date = date.fromtimestamp(float(tweet_time))\n",
    "\n",
    "    print \"Outputting to '%s' ...\" % o_file\n",
    "    np.savetxt('data/' + o_file, output, delimiter=',')\n",
    "\n",
    "    print \"--------------------\"\n",
    "    print \"Total number of tweets %d\" % int(np.sum(output[:, 0]))\n",
    "    print \"Average number of tweets per hour %f\" % np.mean(output[:, 0])\n",
    "    print \"Average number of retweets %f\" % float(np.sum(output[:, 1]) / np.sum(output[:, 0]))\n",
    "    print \"Average number of followers of (%d) users %f\" %\\\n",
    "          (len(user_follower), float(sum(user_follower.values()) / float(len(user_follower))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "history = np.loadtxt('data/#SuperBowlhistogram')\n",
    "hours = np.loadtxt('data/#SuperBowlhistogramlabel')\n",
    "\n",
    "plt.cla()\n",
    "#plt.yscale('log')\n",
    "plt.plot(hours, history)\n",
    "plt.title('#SuperBowl Hourly Tweet Count')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Tweets')\n",
    "\n",
    "plt.xticks(range(len(hours))[::100], hours[::100])\n",
    "plt.savefig('graphs/#SuperBowl_tweet_count_histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "history = np.loadtxt('data/#NFLhistogram')\n",
    "hours = np.loadtxt('data/#NFLhistogramlabel')\n",
    "\n",
    "plt.cla()\n",
    "#plt.yscale('log')\n",
    "plt.plot(hours, history)\n",
    "plt.title('#NFL Hourly Tweet Count')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Tweets')\n",
    "\n",
    "plt.xticks(range(len(hours))[::100], hours[::100])\n",
    "plt.savefig('graphs/#NFL_tweet_count_histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tweets_#gohawks.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -3.431273\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.830944\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  2.305868\n",
      "\t\tT-test feature 6: 26540.184413\n",
      "\t\tT-test feature 7: 645.459722\n",
      "\t\tT-test feature 8: 1392.503026\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.451127\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000026\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.137352\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.137352\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  2.305868\n",
      "\t\tT-test feature 6: 26540.184413\n",
      "\t\tT-test feature 7: 645.459722\n",
      "\t\tT-test feature 8: 1392.503026\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.451127\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000026\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.083056\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.083049\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  2.305868\n",
      "\t\tT-test feature 6: 26540.184413\n",
      "\t\tT-test feature 7: 645.459722\n",
      "\t\tT-test feature 8: 1392.503026\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.451127\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000026\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.941716\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.978351\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 32.254497\n",
      "\t\tT-test feature 2: 12339.208428\n",
      "\t\tT-test feature 3:  2.607192\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  2.305868\n",
      "\t\tT-test feature 6: 26540.184413\n",
      "\t\tT-test feature 7: 645.459722\n",
      "\t\tT-test feature 8: 1392.503026\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.185462\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.182427\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.451127\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000026\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "data/tweets_#gopatriots.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.866516\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.989521\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5: 22.746685\n",
      "\t\tT-test feature 6: 621064.374186\n",
      "\t\tT-test feature 7:       nan\n",
      "\t\tT-test feature 8: 7142.937408\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.572824\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:       nan\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.257283\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.257283\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5: 22.746685\n",
      "\t\tT-test feature 6: 621064.374186\n",
      "\t\tT-test feature 7:       nan\n",
      "\t\tT-test feature 8: 7142.937408\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.572824\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:       nan\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.106411\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.106411\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5: 22.746685\n",
      "\t\tT-test feature 6: 621064.374186\n",
      "\t\tT-test feature 7:       nan\n",
      "\t\tT-test feature 8: 7142.937408\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.572824\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:       nan\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.857947\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.916684\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1:       nan\n",
      "\t\tT-test feature 2: 7148.513718\n",
      "\t\tT-test feature 3:  3.428438\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5: 22.746685\n",
      "\t\tT-test feature 6: 621064.374186\n",
      "\t\tT-test feature 7:       nan\n",
      "\t\tT-test feature 8: 7142.937408\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:       nan\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.181693\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.572824\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:       nan\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "data/tweets_#nfl.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -2.498618\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.978169\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  6.831252\n",
      "\t\tT-test feature 6: 2187.079982\n",
      "\t\tT-test feature 7: 267.385951\n",
      "\t\tT-test feature 8: 1835.564400\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.183349\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.045448\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.045448\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  6.831252\n",
      "\t\tT-test feature 6: 2187.079982\n",
      "\t\tT-test feature 7: 267.385951\n",
      "\t\tT-test feature 8: 1835.564400\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.183349\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.151815\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.151815\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  6.831252\n",
      "\t\tT-test feature 6: 2187.079982\n",
      "\t\tT-test feature 7: 267.385951\n",
      "\t\tT-test feature 8: 1835.564400\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.183349\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -2.148534\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.991687\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 75.215080\n",
      "\t\tT-test feature 2: 1604.618371\n",
      "\t\tT-test feature 3:  3.178866\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  6.831252\n",
      "\t\tT-test feature 6: 2187.079982\n",
      "\t\tT-test feature 7: 267.385951\n",
      "\t\tT-test feature 8: 1835.564400\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.432376\n",
      "\t\tP-value feature 2:  0.000003\n",
      "\t\tP-value feature 3:  0.202118\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.183349\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "data/tweets_#patriots.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -2.291648\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.541453\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  0.425384\n",
      "\t\tT-test feature 6: 196192.985044\n",
      "\t\tT-test feature 7: 4203.146057\n",
      "\t\tT-test feature 8: 3147.501792\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.633074\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.003434\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.057163\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.057163\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  0.425384\n",
      "\t\tT-test feature 6: 196192.985044\n",
      "\t\tT-test feature 7: 4203.146057\n",
      "\t\tT-test feature 8: 3147.501792\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.633074\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.003434\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.089487\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.089484\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  0.425384\n",
      "\t\tT-test feature 6: 196192.985044\n",
      "\t\tT-test feature 7: 4203.146057\n",
      "\t\tT-test feature 8: 3147.501792\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.633074\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.003434\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.912602\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.990319\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 61.083197\n",
      "\t\tT-test feature 2: 19299.952523\n",
      "\t\tT-test feature 3:  1.501174\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  0.425384\n",
      "\t\tT-test feature 6: 196192.985044\n",
      "\t\tT-test feature 7: 4203.146057\n",
      "\t\tT-test feature 8: 3147.501792\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.226676\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.388718\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.633074\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.003434\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "data/tweets_#sb49.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.941199\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.996203\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  3.109246\n",
      "\t\tT-test feature 6: 1401642.010906\n",
      "\t\tT-test feature 7: 32016.027715\n",
      "\t\tT-test feature 8: 8617.255121\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.447412\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.055304\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.055304\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  3.109246\n",
      "\t\tT-test feature 6: 1401642.010906\n",
      "\t\tT-test feature 7: 32016.027715\n",
      "\t\tT-test feature 8: 8617.255121\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.447412\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.084825\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.084825\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  3.109246\n",
      "\t\tT-test feature 6: 1401642.010906\n",
      "\t\tT-test feature 7: 32016.027715\n",
      "\t\tT-test feature 8: 8617.255121\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.447412\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.949693\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.997678\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 243.116177\n",
      "\t\tT-test feature 2: 292994.277252\n",
      "\t\tT-test feature 3:  0.744969\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  3.109246\n",
      "\t\tT-test feature 6: 1401642.010906\n",
      "\t\tT-test feature 7: 32016.027715\n",
      "\t\tT-test feature 8: 8617.255121\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.289677\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.472409\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.447412\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "data/tweets_#superbowl.csv\n",
      "\n",
      "\tLinear Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.102577\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.996959\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  4.231599\n",
      "\t\tT-test feature 6: 169100.241200\n",
      "\t\tT-test feature 7: 22053.868096\n",
      "\t\tT-test feature 8: 9162.252714\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.379419\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLogistic Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: 0.042759\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.042759\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  4.231599\n",
      "\t\tT-test feature 6: 169100.241200\n",
      "\t\tT-test feature 7: 22053.868096\n",
      "\t\tT-test feature 8: 9162.252714\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.379419\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tSupport Vector Regression Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.112585\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: -0.112585\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  4.231599\n",
      "\t\tT-test feature 6: 169100.241200\n",
      "\t\tT-test feature 7: 22053.868096\n",
      "\t\tT-test feature 8: 9162.252714\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.379419\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n",
      "\tLARS Lasso Mean Scores:\n",
      "\t-Problem 2-\n",
      "\t\tR^2 score: -0.098248\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t-Problem 3-\n",
      "\t\tR^2 score: 0.997060\n",
      "\t\t------------------------------\n",
      "\t\tT-test feature 1: 659.440411\n",
      "\t\tT-test feature 2: 30766.778560\n",
      "\t\tT-test feature 3:  0.908156\n",
      "\t\tT-test feature 4:       nan\n",
      "\t\tT-test feature 5:  4.231599\n",
      "\t\tT-test feature 6: 169100.241200\n",
      "\t\tT-test feature 7: 22053.868096\n",
      "\t\tT-test feature 8: 9162.252714\n",
      "\t\t------------------------------\n",
      "\t\tP-value feature 1:  0.302070\n",
      "\t\tP-value feature 2:  0.000000\n",
      "\t\tP-value feature 3:  0.422320\n",
      "\t\tP-value feature 4:       nan\n",
      "\t\tP-value feature 5:  0.379419\n",
      "\t\tP-value feature 6:  0.000000\n",
      "\t\tP-value feature 7:  0.000000\n",
      "\t\tP-value feature 8:  0.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Problem 2 and 3\n",
    "from os import listdir\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import LassoLars as lasso\n",
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.feature_selection import f_regression as freg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directory name\n",
    "path = 'data/'\n",
    "\n",
    "# hashtag name\n",
    "hashtag = []\n",
    "\n",
    "# csv file name\n",
    "csv = []\n",
    "\n",
    "files = listdir(path)\n",
    "\n",
    "# append csv names into list\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        hashtag.append(f[7:-4])\n",
    "        csv.append(path + f)\n",
    "\n",
    "# start the training per hashtag file\n",
    "\n",
    "col_names = [\"n_tweets\", \"n_retweets\", \"sum_followers\", \"max_followers\", \"hour\", \"avg_tweet_per_user\", \"n_users\", \"n_users_3\", \"n_len_100\"]\n",
    "for c in csv:\n",
    "    print(c + \"\\n\")\n",
    "    csv_df = pd.read_csv(c, header=None, names=col_names)\n",
    "    # aggregate by hour of day\n",
    "    csv_df.sort_values(by='hour')\n",
    "    \n",
    "    LR2score = []\n",
    "    LR2fval = np.array([0,0,0,0])\n",
    "    LR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    LR3score = []\n",
    "    LR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    LR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    LogR2score = []\n",
    "    LogR2fval = np.array([0,0,0,0])\n",
    "    LogR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    LogR3score = []\n",
    "    LogR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    LogR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    SVR2score = []\n",
    "    SVR2fval = np.array([0,0,0,0])\n",
    "    SVR2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    SVR3score = []\n",
    "    SVR3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    SVR3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    Lasso2score = []\n",
    "    Lasso2fval = np.array([0,0,0,0])\n",
    "    Lasso2pval = np.array([0,0,0,0])\n",
    "    \n",
    "    Lasso3score = []\n",
    "    Lasso3fval = np.array([0,0,0,0,0,0,0,0])\n",
    "    Lasso3pval = np.array([0,0,0,0,0,0,0,0])\n",
    "    \n",
    "    for hr in range(0,23):\n",
    "        #train data setup\n",
    "        data_prev = csv_df[csv_df['hour'] == hr].copy()\n",
    "        #features\n",
    "        data2X_train = data_prev[['n_retweets','sum_followers', 'max_followers', 'hour']].copy()\n",
    "        data3X_train = data_prev[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "        #targets\n",
    "        data2Y_train = data_prev[['n_tweets']].copy()\n",
    "        data3Y_train = data_prev[['n_tweets']].copy()\n",
    "        \n",
    "        #test data setup\n",
    "        data_next = csv_df[csv_df['hour'] == hr+1].copy()\n",
    "        #features\n",
    "        data2X_test = data_next[['n_retweets','sum_followers', 'max_followers', 'hour']].copy()\n",
    "        data3X_test = data_next[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "        #targets\n",
    "        data2Y_test = data_next[['n_tweets']].copy()\n",
    "        data3Y_test = data_next[['n_tweets']].copy()\n",
    "        \n",
    "        #create models\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "        LR2model = LR()\n",
    "        LR3model = LR()\n",
    "        #http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "        LogR2model = LogR()\n",
    "        LogR3model = LogR()\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "        SVR2model = SVR()\n",
    "        SVR3model = SVR()\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html\n",
    "        # Note for whoever writes report: LARS stands for Least Angle Regression\n",
    "        Lasso2model = lasso()\n",
    "        Lasso3model = lasso()\n",
    "        \n",
    "        #fit models\n",
    "        LR2model.fit(data2X_train, data2Y_train)\n",
    "        LR3model.fit(data3X_train, data3Y_train)\n",
    "        LogR2model.fit(data2X_train, data2Y_train.unstack())\n",
    "        LogR3model.fit(data3X_train, data3Y_train.unstack())\n",
    "        SVR2model.fit(data2X_train, data2Y_train.unstack())\n",
    "        SVR3model.fit(data3X_train, data3Y_train.unstack())\n",
    "        Lasso2model.fit(data2X_train, data2Y_train)\n",
    "        Lasso3model.fit(data3X_train, data3Y_train)\n",
    "        \n",
    "        #score models using r^2 scoring, f/t value and p value\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\n",
    "        \n",
    "        #problem 2 Lin Reg\n",
    "        LR2score.append(LR2model.score(data2X_test, data2Y_test))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        LR2fval = LR2fval + f\n",
    "        LR2pval = LR2pval + p\n",
    "        \n",
    "        #problem 3 Lin Reg\n",
    "        LR3score.append(LR3model.score(data3X_test, data3Y_test))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        LR3fval = LR3fval + f\n",
    "        LR3pval = LR3pval + p\n",
    "        \n",
    "        #problem 2 Log Reg\n",
    "        LogR2score.append(LogR2model.score(data2X_test, data2Y_test.unstack()))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        LogR2fval = LogR2fval + f\n",
    "        LogR2pval = LogR2pval + p\n",
    "        \n",
    "        #problem 3 Log Reg\n",
    "        LogR3score.append(LogR3model.score(data3X_test, data3Y_test.unstack()))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        LogR3fval = LogR3fval + f\n",
    "        LogR3pval = LogR3pval + p\n",
    "        \n",
    "        #problem 2 SVR \n",
    "        SVR2score.append(SVR2model.score(data2X_test, data2Y_test.unstack()))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        SVR2fval = SVR2fval + f\n",
    "        SVR2pval = SVR2pval + p\n",
    "        \n",
    "        #problem 3 SVR \n",
    "        SVR3score.append(SVR3model.score(data3X_test, data3Y_test.unstack()))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        SVR3fval = SVR3fval + f\n",
    "        SVR3pval = SVR3pval + p\n",
    "        \n",
    "        #problem 2 lARS\n",
    "        Lasso2score.append(Lasso2model.score(data2X_test, data2Y_test))\n",
    "        f, p = freg(data2X_test, data2Y_test.unstack())\n",
    "        Lasso2fval = Lasso2fval + f\n",
    "        Lasso2pval = Lasso2pval + p\n",
    "        \n",
    "        #problem 3 lARS\n",
    "        Lasso3score.append(Lasso3model.score(data3X_test, data3Y_test))\n",
    "        f, p = freg(data3X_test, data3Y_test.unstack())\n",
    "        predicted = Lasso3model.predict(data3X_test)\n",
    "        Lasso3fval = Lasso3fval + f\n",
    "        Lasso3pval = Lasso3pval + p\n",
    "    \n",
    "    # print results\n",
    "    print(\"\\tLinear Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tLogistic Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LogR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LogR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LogR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LogR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LogR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(LogR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(LogR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(LogR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(LogR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(LogR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tSupport Vector Regression Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(SVR2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(SVR2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(SVR2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(SVR2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(SVR2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(SVR3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(SVR3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(SVR3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(SVR3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(SVR3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"\\tLARS Lasso Mean Scores:\")\n",
    "    print(\"\\t-Problem 2-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(Lasso2score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(Lasso2fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(Lasso2score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(Lasso2pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(Lasso2score)))\n",
    "    print(\"\\t-Problem 3-\")\n",
    "    print(\"\\t\\tR^2 score: %5f\" % np.mean(Lasso3score))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, f in enumerate(Lasso3fval):\n",
    "        print(\"\\t\\tT-test feature %d: %9f\" % (num+1, f/len(Lasso3score)))\n",
    "    print(\"\\t\\t\" + \"-\"*30)\n",
    "    for num, p in enumerate(Lasso3pval):\n",
    "        print(\"\\t\\tP-value feature %d: %9f\" % (num+1, p/len(Lasso3score)))\n",
    "    print('\\n')\n",
    "    \n",
    "    # Graph predicted vs feature count\n",
    "    plt.cla()\n",
    "    #plt.yscale('log')\n",
    "    plt.scatter(data3X_test[['sum_followers']], predicted)\n",
    "    plt.title('Tweet Count vs sum_followers')\n",
    "    plt.xlabel('sum_followers')\n",
    "    plt.ylabel(c+'Number of Tweets')\n",
    "\n",
    "    plt.savefig('graphs/count_vs_sum_'+c[5:-4])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.cla()\n",
    "    #plt.yscale('log')\n",
    "    plt.scatter(data3X_test[['sum_followers']], predicted)\n",
    "    plt.title('Tweet Count vs n_users')\n",
    "    plt.xlabel('sum_followers')\n",
    "    plt.ylabel(c+'Number of Tweets')\n",
    "\n",
    "    plt.savefig('graphs/count_vs_n_users_'+c[5:-4])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.cla()\n",
    "    #plt.yscale('log')\n",
    "    plt.scatter(data3X_test[['sum_followers']], predicted)\n",
    "    plt.title('Tweet Count vs n_len_100')\n",
    "    plt.xlabel('sum_followers')\n",
    "    plt.ylabel(c+'Number of Tweets')\n",
    "\n",
    "    plt.savefig('graphs/count_vs_n_len_100_'+c[5:-4])\n",
    "    plt.show()\n",
    "    \n",
    "    #break #remove to run all for all files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tweets_#gohawks.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 27.448149:\n",
      "\tAverage prediction error for Period 2 36.383078:\n",
      "\tAverage prediction error for Period 3 16.337346:\n",
      "------------------------------------------------------------\n",
      "data/tweets_#gopatriots.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 61.608437:\n",
      "\tAverage prediction error for Period 2 65.836415:\n",
      "\tAverage prediction error for Period 3 10.785898:\n",
      "------------------------------------------------------------\n",
      "data/tweets_#nfl.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 51.328586:\n",
      "\tAverage prediction error for Period 2 170.605770:\n",
      "\tAverage prediction error for Period 3 27.154346:\n",
      "------------------------------------------------------------\n",
      "data/tweets_#patriots.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 84.086567:\n",
      "\tAverage prediction error for Period 2 65.676033:\n",
      "\tAverage prediction error for Period 3 16.494728:\n",
      "------------------------------------------------------------\n",
      "data/tweets_#sb49.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 3436.743379:\n",
      "\tAverage prediction error for Period 2 1964.359263:\n",
      "\tAverage prediction error for Period 3 40.565964:\n",
      "------------------------------------------------------------\n",
      "data/tweets_#superbowl.csv\n",
      "\n",
      "\tAverage prediction error for Period 1 542.311391:\n",
      "\tAverage prediction error for Period 2 1533.897981:\n",
      "\tAverage prediction error for Period 3 212.234838:\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### problem 4\n",
    "#1) 0-7\n",
    "#2) 8-19\n",
    "#3) 20-23\n",
    "from os import listdir\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import LassoLars as lasso\n",
    "from sklearn.linear_model import LogisticRegression as LogR\n",
    "from sklearn.feature_selection import f_regression as freg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "from sklearn.cross_validation import cross_val_score as cv\n",
    "\n",
    "# directory name\n",
    "path = 'data/'\n",
    "\n",
    "# hashtag name\n",
    "hashtag = []\n",
    "\n",
    "# csv file name\n",
    "csv = []\n",
    "\n",
    "files = listdir(path)\n",
    "\n",
    "# append csv names into list\n",
    "for f in files:\n",
    "    if f.endswith(\".csv\"):\n",
    "        hashtag.append(f[7:-4])\n",
    "        csv.append(path + f)\n",
    "\n",
    "# start the training per hashtag file\n",
    "\n",
    "col_names = [\"n_tweets\", \"n_retweets\", \"sum_followers\", \"max_followers\", \"hour\", \"avg_tweet_per_user\", \"n_users\", \"n_users_3\", \"n_len_100\"]\n",
    "for c in csv:\n",
    "    print(c + \"\\n\")\n",
    "    csv_df = pd.read_csv(c, header=None, names=col_names)\n",
    "    # aggregate by hour of day\n",
    "    csv_df.sort_values(by='hour')\n",
    "    period1 = csv_df[csv_df['hour'] < 8].copy()\n",
    "    period2 = csv_df[csv_df['hour'] > 7].copy()\n",
    "    period2 = period2[period2['hour']<20].copy()\n",
    "    period3 = csv_df[csv_df['hour'] > 19].copy()\n",
    "    \n",
    "    period1_feat = period1[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "    period1_tar = period1[['n_tweets']].copy()\n",
    "    period2_feat = period2[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "    period2_tar = period2[['n_tweets']].copy()\n",
    "    period3_feat = period3[['n_retweets','sum_followers', 'max_followers', 'hour', 'avg_tweet_per_user', 'n_users', 'n_users_3', 'n_len_100']].copy()\n",
    "    period3_tar = period3[['n_tweets']].copy()\n",
    "    \n",
    "    model = lasso()\n",
    "    score1 = cv(model, period1_feat, period1_tar, scoring='mean_squared_error', cv=10, n_jobs=1)\n",
    "    score2 = cv(model, period2_feat, period2_tar, scoring='mean_squared_error', cv=10, n_jobs=1)\n",
    "    score3 = cv(model, period3_feat, period3_tar, scoring='mean_squared_error', cv=10, n_jobs=1)\n",
    "    \n",
    "    print(\"\\tAverage prediction error for Period 1 %f:\" % m.sqrt(abs(np.mean(score1))))\n",
    "    print(\"\\tAverage prediction error for Period 2 %f:\" % m.sqrt(abs(np.mean(score2))))\n",
    "    print(\"\\tAverage prediction error for Period 3 %f:\" % m.sqrt(abs(np.mean(score3))))\n",
    "    print(\"-\"*60)\n",
    "    #break #remove to run all hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tweets</th>\n",
       "      <th>n_retweets</th>\n",
       "      <th>sum_followers</th>\n",
       "      <th>max_followers</th>\n",
       "      <th>hour</th>\n",
       "      <th>avg_tweet_per_user</th>\n",
       "      <th>n_users</th>\n",
       "      <th>n_users_3</th>\n",
       "      <th>n_len_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>749230320</td>\n",
       "      <td>749230320</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26556905</td>\n",
       "      <td>26556905</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266124599</td>\n",
       "      <td>266124599</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>852924882</td>\n",
       "      <td>783479653</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>570307870</td>\n",
       "      <td>570307870</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1040232535</td>\n",
       "      <td>1040232535</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2374402878</td>\n",
       "      <td>2374402878</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>310526755</td>\n",
       "      <td>310526755</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2153808620</td>\n",
       "      <td>2153808620</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2450904997</td>\n",
       "      <td>2450904997</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144269935</td>\n",
       "      <td>144269935</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>2419495681</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>552311335</td>\n",
       "      <td>552311335</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28271579</td>\n",
       "      <td>28271579</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2951693489</td>\n",
       "      <td>2951693489</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2562864635</td>\n",
       "      <td>2562864635</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1681443624</td>\n",
       "      <td>1681443624</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>339568235</td>\n",
       "      <td>339568235</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>959806075</td>\n",
       "      <td>959806075</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2652194204</td>\n",
       "      <td>2652194204</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>241913743</td>\n",
       "      <td>208804056</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>276840270</td>\n",
       "      <td>276840270</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>640522942</td>\n",
       "      <td>616880568</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2374402878</td>\n",
       "      <td>2374402878</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>602785190</td>\n",
       "      <td>384115132</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2854889736</td>\n",
       "      <td>2854889736</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23642374</td>\n",
       "      <td>23642374</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2795557638</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>14</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2803153127</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>15</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3555832380</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>16</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3991791642</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>17</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5177606002</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6083456298</td>\n",
       "      <td>2955210056</td>\n",
       "      <td>19</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2715135450</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5534258536</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>9</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3237255532</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>10</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4120975790</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>11</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7207555358</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2941132527</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>13</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16590943</td>\n",
       "      <td>16590943</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3837221178</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3557216156</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2449337144</td>\n",
       "      <td>1341412009</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2726170316</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>18</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3596359833</td>\n",
       "      <td>2367821323</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3046227962</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>8</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5725870230</td>\n",
       "      <td>3010734780</td>\n",
       "      <td>9</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3997777792</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3791695135</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>11</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4358197571</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>12</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>918146467</td>\n",
       "      <td>918146467</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2822590588</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6191320567</td>\n",
       "      <td>3015729825</td>\n",
       "      <td>15</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376580093</td>\n",
       "      <td>376580093</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66396874</td>\n",
       "      <td>66396874</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2732366726</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4664503418</td>\n",
       "      <td>2691199254</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_tweets  n_retweets  sum_followers  max_followers  hour  \\\n",
       "0           1           2      749230320      749230320    14   \n",
       "3           1           0       26556905       26556905    11   \n",
       "4           1           0     2419495681     2419495681    12   \n",
       "5           1           1     2419495681     2419495681    16   \n",
       "6           1           1      266124599      266124599    10   \n",
       "7           2           2      852924882      783479653    16   \n",
       "8           1           1      570307870      570307870     8   \n",
       "9           1           2     1040232535     1040232535    11   \n",
       "10          1           0     2419495681     2419495681    17   \n",
       "11          1           1     2374402878     2374402878    10   \n",
       "12          1           0      310526755      310526755    11   \n",
       "13          1           0     2153808620     2153808620    17   \n",
       "14          1           0     2450904997     2450904997     8   \n",
       "15          1           0      144269935      144269935     9   \n",
       "16          1           0     2419495681     2419495681    12   \n",
       "17          1           0      552311335      552311335    14   \n",
       "18          1           0       28271579       28271579    17   \n",
       "21          1           0     2951693489     2951693489     8   \n",
       "22          1           0     2562864635     2562864635     9   \n",
       "23          1           0     1681443624     1681443624    13   \n",
       "24          1           0      339568235      339568235    19   \n",
       "26          1           0      959806075      959806075    15   \n",
       "27          1           0     2652194204     2652194204    17   \n",
       "28          2           0      241913743      208804056    14   \n",
       "29          1          58      276840270      276840270    12   \n",
       "30          2           0      640522942      616880568    14   \n",
       "31          1           0     2374402878     2374402878    16   \n",
       "32          2           0      602785190      384115132    17   \n",
       "34          1           1     2854889736     2854889736    12   \n",
       "35          1           0       23642374       23642374    15   \n",
       "..        ...         ...            ...            ...   ...   \n",
       "625         6           0     2795557638     2691199254    14   \n",
       "626         8           0     2803153127     2691199254    15   \n",
       "627         8           0     3555832380     2691199254    16   \n",
       "628         7           0     3991791642     2691199254    17   \n",
       "629         8           0     5177606002     2691199254    18   \n",
       "630         7           0     6083456298     2955210056    19   \n",
       "641         8           0     2715135450     2691199254     8   \n",
       "642         6           0     5534258536     2691199254     9   \n",
       "643         4           0     3237255532     2691199254    10   \n",
       "644         6           0     4120975790     2691199254    11   \n",
       "645         7           2     7207555358     2691199254    12   \n",
       "646         7           0     2941132527     2691199254    13   \n",
       "647         1           0       16590943       16590943    14   \n",
       "648         4           0     3837221178     2691199254    15   \n",
       "649         3           0     3557216156     2691199254    16   \n",
       "650         3           0     2449337144     1341412009    17   \n",
       "651         4           0     2726170316     2691199254    18   \n",
       "652         2           0     3596359833     2367821323    19   \n",
       "664         4           0     3046227962     2691199254     8   \n",
       "665         5           0     5725870230     3010734780     9   \n",
       "666         4           0     3997777792     2691199254    10   \n",
       "667         6           0     3791695135     2691199254    11   \n",
       "668         9           1     4358197571     2691199254    12   \n",
       "669         1           0      918146467      918146467    13   \n",
       "670         3           0     2822590588     2691199254    14   \n",
       "671         6           0     6191320567     3015729825    15   \n",
       "672         1           0      376580093      376580093    16   \n",
       "673         1           0       66396874       66396874    17   \n",
       "674         2           0     2732366726     2691199254    18   \n",
       "675         2           0     4664503418     2691199254    19   \n",
       "\n",
       "     avg_tweet_per_user  n_users  n_users_3  n_len_100  \n",
       "0              1.000000        1          0          0  \n",
       "3              1.000000        1          0          1  \n",
       "4              1.000000        1          0          1  \n",
       "5              1.000000        1          0          1  \n",
       "6              1.000000        1          0          0  \n",
       "7              1.000000        2          0          2  \n",
       "8              1.000000        1          0          0  \n",
       "9              1.000000        1          0          1  \n",
       "10             1.000000        1          0          1  \n",
       "11             1.000000        1          0          1  \n",
       "12             1.000000        1          0          0  \n",
       "13             1.000000        1          0          0  \n",
       "14             1.000000        1          0          0  \n",
       "15             1.000000        1          0          0  \n",
       "16             1.000000        1          0          1  \n",
       "17             1.000000        1          0          1  \n",
       "18             1.000000        1          0          0  \n",
       "21             1.000000        1          0          1  \n",
       "22             1.000000        1          0          1  \n",
       "23             1.000000        1          0          1  \n",
       "24             1.000000        1          0          1  \n",
       "26             1.000000        1          0          0  \n",
       "27             1.000000        1          0          0  \n",
       "28             1.000000        2          0          2  \n",
       "29             1.000000        1          0          1  \n",
       "30             1.000000        2          0          2  \n",
       "31             1.000000        1          0          1  \n",
       "32             1.000000        2          0          2  \n",
       "34             1.000000        1          0          1  \n",
       "35             1.000000        1          0          1  \n",
       "..                  ...      ...        ...        ...  \n",
       "625            2.000000        3          1          3  \n",
       "626            2.666667        3          1          6  \n",
       "627            1.333333        6          0          6  \n",
       "628            1.400000        5          1          5  \n",
       "629            2.000000        4          1          5  \n",
       "630            1.166667        6          0          5  \n",
       "641            4.000000        2          1          5  \n",
       "642            1.200000        5          0          5  \n",
       "643            1.333333        3          0          4  \n",
       "644            2.000000        3          1          3  \n",
       "645            1.000000        7          0          5  \n",
       "646            2.333333        3          1          5  \n",
       "647            1.000000        1          0          0  \n",
       "648            1.000000        4          0          3  \n",
       "649            1.000000        3          0          3  \n",
       "650            1.000000        3          0          2  \n",
       "651            1.333333        3          0          2  \n",
       "652            1.000000        2          0          2  \n",
       "664            1.333333        3          0          1  \n",
       "665            1.666667        3          1          3  \n",
       "666            1.000000        4          0          4  \n",
       "667            1.500000        4          0          4  \n",
       "668            1.800000        5          1          5  \n",
       "669            1.000000        1          0          1  \n",
       "670            1.000000        3          0          2  \n",
       "671            1.200000        5          0          3  \n",
       "672            1.000000        1          0          0  \n",
       "673            1.000000        1          0          1  \n",
       "674            1.000000        2          0          1  \n",
       "675            1.000000        2          0          1  \n",
       "\n",
       "[369 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
